{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ce31ea-1e84-4f6c-99f0-847e7a5d1400",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "from typing import *\n",
    "import multiprocessing\n",
    "from pathlib import Path\n",
    "from goatools.obo_parser import GODag\n",
    "from goatools.go_enrichment import GOEnrichmentStudy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4a76c2-4f17-49a2-9f02-1cc4ddfc2350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base directory where files are stored\n",
    "base_dir = Path('/storage/group/izg5139/default/lefteris/')\n",
    "\n",
    "# Multi Species Gene Ontology Enrichmert Analysis input directory\n",
    "multi_species_goea_files_dir = base_dir / 'multi_species_goea_files'\n",
    "\n",
    "# Output directories setup\n",
    "input_dirs = {\n",
    "    'goea_results': multi_species_goea_files_dir / 'multi_species_goea_results',\n",
    "    'phylum_associations': multi_species_goea_files_dir / 'phylum_associations',\n",
    "    'phylum_study_populations': multi_species_goea_files_dir / 'phylum_study_populations',\n",
    "    'phylum_background_populations': multi_species_goea_files_dir / 'phylum_background_populations'\n",
    "}\n",
    "\n",
    "# Multi Species Gene Ontology Enrichmert Analysis output directory\n",
    "multi_species_goea_results_dir = multi_species_goea_files_dir / \"multi_species_goea_results\"\n",
    "\n",
    "def get_phyla_names(directory: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Extracts the Phyla names that will be used later for the Multi-Species Gene Ontology Enrichment Analysis\n",
    "    \"\"\"\n",
    "    # Get all files ending in .json\n",
    "    phylum_json_files = [f for f in os.listdir(directory) if f.endswith('.json')]\n",
    "    \n",
    "    # Split filenames on _study and store first part\n",
    "    phyla_names = [f.split('_study')[0] for f in phylum_json_files]\n",
    "    \n",
    "    return phyla_names\n",
    "\n",
    "phyla_names = get_phyla_names(input_dirs['phylum_study_populations'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13906c3-10c3-4ba4-b041-9e8045ce7972",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_multi_species_goea(study_populations, background_populations, associations, taxon_id: int) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Performs Gene Ontology enrichment analysis (GOEA) for a specific species/taxon.\n",
    "    It is meant to be used later for a Multi Species Gene Ontology Enrichment Analysis.\n",
    "    \n",
    "    This function analyzes whether certain GO terms are statistically overrepresented\n",
    "    in a study set comprised of Quasi Prime containting proteins compared to a background set of GO Term annotated proteins.\n",
    "    \n",
    "    \"\"\"\n",
    "    # Load the Gene Ontology graph structure from OBO file\n",
    "    go_obo = GODag(multi_species_goea_files_dir / \"go-basic.obo\", prt=None)\n",
    "    \n",
    "    # Extract the relevant data for the specified Taxon ID\n",
    "    taxon_study_population = study_populations[taxon_id]\n",
    "    taxon_background_population = background_populations[taxon_id]\n",
    "    taxon_associations = associations[taxon_id]\n",
    "    \n",
    "    # Initialize the GO enrichment study object\n",
    "    go_study = GOEnrichmentStudy(\n",
    "        taxon_background_population, \n",
    "        taxon_associations, \n",
    "        go_obo,\n",
    "        propagate_counts=False, # Don't propagate counts up the GO hierarchy\n",
    "        alpha=0.05, # Significance threshold\n",
    "        methods=['fdr_bh'] # Use Benjamini-Hochberg FDR correction\n",
    "    )\n",
    "    \n",
    "    # Perform the enrichment analysis\n",
    "    go_results = go_study.run_study(taxon_study_population, prt=None)\n",
    "    # Filter for nominally significant results (p < 0.05)\n",
    "    go_results = [r for r in go_results if r.p_uncorrected < 0.05]\n",
    "    \n",
    "    # Return an empty Polars DataFrame if no results are obtained\n",
    "    if not go_results:\n",
    "        return pl.DataFrame()\n",
    "\n",
    "    # Process results and calculate additional statistics\n",
    "    go_results_list = []\n",
    "    N_background = len(taxon_background_population)\n",
    "    \n",
    "    for r in go_results:\n",
    "    # Calculate odds ratio components with continuity correction (+0.5)\n",
    "        a = r.study_count + 0.5  # Number in study set with GO term\n",
    "        b = r.study_n - r.study_count + 0.5 # Number in study set without GO term\n",
    "        c = r.pop_count - r.study_count + 0.5 # Number in background with GO term (excluding study set)\n",
    "        d = N_background - r.pop_count - (r.study_n - r.study_count) + 0.5 # Number in background without GO term\n",
    "\n",
    "        # Calculate effect size statistics\n",
    "        odds_ratio = (a * d) / (b * c)\n",
    "        log_odds_ratio = np.log(odds_ratio)\n",
    "        se_log_odds_ratio = np.sqrt(1/a + 1/b + 1/c + 1/d) # Standard error of log odds ratio\n",
    "\n",
    "        # Compile results for this GO term\n",
    "        result_dict = {\n",
    "            'GO_term': r.goterm.id,\n",
    "            'Description': r.goterm.name,\n",
    "            'Class': r.goterm.namespace,  # Biological Process, Molecular Function, or Cellular Component\n",
    "            'P_value': r.p_uncorrected,\n",
    "            'Adjusted_p_value': r.p_fdr_bh,  # Benjamini-Hochberg corrected p-value\n",
    "            'N_protein': r.study_count,  # Number of proteins with this GO term in study set\n",
    "            'N_study': r.study_n,  # Total number of proteins in study set\n",
    "            'N_GO': r.pop_count,  # Number of proteins with this GO term in background\n",
    "            'N_background': N_background,  # Total number of proteins in background\n",
    "            'Fold_enrichment': (r.study_count * N_background) / (r.study_n * r.pop_count),  # Enrichment ratio\n",
    "            'Odds_ratio': odds_ratio,\n",
    "            'Log_odds_ratio': log_odds_ratio,\n",
    "            'SE_log_odds_ratio': se_log_odds_ratio,\n",
    "            'Taxon_ID': taxon_id\n",
    "        }\n",
    "        go_results_list.append(result_dict)\n",
    "\n",
    "    # Convert results to polars DataFrame\n",
    "    go_results_df = pl.DataFrame(go_results_list)\n",
    "\n",
    "    return go_results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f444f7e-1bd3-4579-9500-e123b95d7ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_phylum(phylum_name: str):\n",
    "    \"\"\"\n",
    "    Process Gene Ontology Enrichment Analysis (GOEA) for all species within a phylum.\n",
    "    \n",
    "    This function loads the necessary data files for a given phylum, performs GOEA\n",
    "    for each species (taxon) within that phylum, and writes the results to files.\n",
    "    \n",
    "    Also, stores taxa that do not have results and writes to an empty results file per Phylum.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Construct file paths for input data using predefined directory structure\n",
    "    phylum_associations_path = input_dirs['phylum_associations'] / f\"{phylum_name}_associations.json\"\n",
    "    phylum_study_populations_path = input_dirs['phylum_study_populations'] / f\"{phylum_name}_study_populations.json\"\n",
    "    phylum_background_populations_path = input_dirs['phylum_background_populations'] / f\"{phylum_name}_background_populations.json\"\n",
    "                                               \n",
    "    # Define output file paths for results and empty results\n",
    "    results_file = multi_species_goea_results_dir / f\"{phylum_name}_multi_species_goea_results.txt\"\n",
    "    empty_results_file = multi_species_goea_results_dir / f\"{phylum_name}_empty_results.txt\"\n",
    "    \n",
    "    # Load protein-GO term associations for all taxa in the phylum\n",
    "    # Convert taxon IDs from strings to integers for consistency\n",
    "    with open(phylum_associations_path, 'r') as f:\n",
    "        associations = json.load(f)\n",
    "        associations = {\n",
    "            int(taxon_id): protein_dict \n",
    "            for taxon_id, protein_dict in associations.items()\n",
    "        }\n",
    "    \n",
    "    # Load study population (proteins of interest) for each taxon\n",
    "    with open(phylum_study_populations_path, 'r') as f:\n",
    "        study_populations = json.load(f)\n",
    "        study_populations = {\n",
    "            int(taxon_id): protein_list \n",
    "            for taxon_id, protein_list in study_populations.items()\n",
    "        }\n",
    "    \n",
    "    # Load background population (all proteins) for each taxon\n",
    "    with open(phylum_background_populations_path, 'r') as f:\n",
    "        background_populations = json.load(f)\n",
    "        background_populations = {\n",
    "            int(taxon_id): protein_list \n",
    "            for taxon_id, protein_list in background_populations.items()\n",
    "        }\n",
    "    \n",
    "    # Track taxa with no significant results or errors\n",
    "    empty_results = []\n",
    "    all_results = []  # Store all valid results to write at once\n",
    "    \n",
    "    # Process each taxon in the phylum\n",
    "    taxon_ids = list(study_populations.keys())\n",
    "    for taxon_id in taxon_ids:\n",
    "        try:\n",
    "            # Perform GO enrichment analysis for this taxon\n",
    "            result = perform_multi_species_goea(study_populations, background_populations, associations, taxon_id)\n",
    "            \n",
    "            if not result.is_empty():\n",
    "                # Store valid results\n",
    "                all_results.append(result)\n",
    "            else:\n",
    "                # Track taxa with no significant results\n",
    "                empty_results.append({\"Phylum\": phylum_name, \"Taxon_ID\": taxon_id})\n",
    "                \n",
    "        except Exception as e:\n",
    "            # Log and track any errors during processing\n",
    "            print(f\"Error processing taxon_id {taxon_id} in {phylum_name}: {str(e)}\")\n",
    "            empty_results.append({\"Phylum\": phylum_name, \"Taxon_ID\": taxon_id})\n",
    "    \n",
    "    # Write all valid results at once if any exist\n",
    "    if all_results:\n",
    "        # Concatenate all results into a single DataFrame\n",
    "        combined_results = pl.concat(all_results)\n",
    "        # Write to file with tab separator\n",
    "        combined_results.write_csv(results_file, separator='\\t')\n",
    "    else:\n",
    "        # No valid results for any taxa\n",
    "        empty_results.append({\"Phylum\": phylum_name, \"Taxon_ID\": \"All\"})\n",
    "    \n",
    "    # Write list of taxa with no results to separate file if any exist\n",
    "    if empty_results:\n",
    "        empty_df = pl.DataFrame(empty_results)\n",
    "        empty_df.write_csv(empty_results_file, separator='\\t')\n",
    "\n",
    "# Main execution block for parallel processing\n",
    "if __name__ == '__main__':\n",
    "    total_phyla = len(phyla_names)\n",
    "    \n",
    "    print(f\"Starting processing {total_phyla} phyla\")\n",
    "    \n",
    "    # Create a process pool and distribute phyla processing across cores\n",
    "    with multiprocessing.Pool() as pool:\n",
    "        # Process results as they complete (order doesn't matter), hence the imap_unordered\n",
    "        for i, _ in enumerate(pool.imap_unordered(process_phylum, phyla_names), 1):\n",
    "            print(f\"Completed {i}/{total_phyla} phyla\")\n",
    "            \n",
    "    print(\"All processing completed\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af383b69-d8c6-48ab-94f9-ac386430396f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import glob\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "from typing import *\n",
    "from pathlib import Path\n",
    "from scipy.stats import t\n",
    "from numpy.typing import NDArray\n",
    "from statsmodels.stats.multitest import multipletests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed74d67-18e2-4f4c-a30a-5c209e90dac8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Base directory for data storage\n",
    "base_dir = Path(\"/storage/group/izg5139/default/lefteris/\")\n",
    "\n",
    "# Set input and output directories\n",
    "mspeea_results_dir = base_dir / \"multi_species_entry_enrichment_files\" / \"multi_species_entry_enrichment_results\"\n",
    "msgoea_results_dir = base_dir / \"multi_species_goea_files\" / \"multi_species_goea_results\"\n",
    "\n",
    "entry_results_dir = {\n",
    "    \"domains\": mspeea_results_dir / 'domain_enrichment_results',\n",
    "    \"families\": mspeea_results_dir / 'family_enrichment_results'\n",
    "}\n",
    "\n",
    "output_dirs = {\n",
    "    \"combined_domains\": mspeea_results_dir / 'combined_domain_enrichment_results',\n",
    "    \"combined_families\": mspeea_results_dir / 'combined_family_enrichment_results',\n",
    "    \"combined_go_terms\": msgoea_results_dir / 'combined_gene_ontology_results'\n",
    "}\n",
    "\n",
    "# Create all output directories\n",
    "for dir_path in output_dirs.values():\n",
    "    os.makedirs(dir_path, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cb4f1a-c480-4f7f-bfe2-26bc6ea7391a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_taxon_count(df: pl.DataFrame) -> bool:\n",
    "    \"\"\"\n",
    "    Check how many unique taxon IDs are in the phylum DataFrame.\n",
    "    \"\"\"\n",
    "    if df.is_empty():\n",
    "        return False \n",
    "        \n",
    "    unique_taxa_count = df['Taxon_ID'].n_unique()\n",
    "    \n",
    "    # Returns a boolean True or False if the taxon count is equal to 1\n",
    "    return unique_taxa_count == 1\n",
    "\n",
    "def process_single_taxon_data(enrichment_df: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Process data when there's only one taxon ID.\n",
    "    Adds percentage calculation but skips random effects model, for single taxon-data.\n",
    "    \"\"\"\n",
    "    # Filter significant entries based on Odds Ratio\n",
    "    significant_df = enrichment_df.filter(pl.col('Odds_Ratio') >= 1)\n",
    "    \n",
    "    # Add Species_Count and Species_Percentage columns (will be 1 and 100 respectively)\n",
    "    result_df = significant_df.with_columns([\n",
    "        pl.lit(1).alias('Species_Count'),\n",
    "        pl.lit(100.0).alias('Species_Percentage')\n",
    "    ])\n",
    "    \n",
    "    # Group by Entry and create lists of values while preserving necessary columns\n",
    "    grouped_df = result_df.group_by('Entry').agg([\n",
    "        pl.col('Interpro_ID').first().alias('Interpro_ID'),\n",
    "        pl.col('Log_Odds_Ratio').alias('Log_Odds_Ratio_List'),\n",
    "        pl.col('SE_Log_Odds_Ratio').alias('SE_Log_Odds_Ratio_List'),\n",
    "        pl.col('P_Value').first().alias('P_Value'),\n",
    "        pl.col('Odds_Ratio').first().alias('Odds_Ratio')\n",
    "    ])\n",
    "    \n",
    "    # Select and order columns to match the multi-species output format\n",
    "    final_df = grouped_df.select([\n",
    "        'Entry',\n",
    "        'Interpro_ID',\n",
    "        pl.lit(1).alias('Species_Count'),\n",
    "        pl.lit(100.0).alias('Species_Percentage'),\n",
    "        pl.col('Log_Odds_Ratio_List').list.first().alias('Combined_Log_Odds_Ratio'),\n",
    "        pl.col('SE_Log_Odds_Ratio_List').list.first().alias('Combined_SE'),\n",
    "        pl.col('P_Value'),\n",
    "        pl.col('P_Value').alias('Adjusted_Meta_P_Value'),\n",
    "        'Log_Odds_Ratio_List',\n",
    "        'SE_Log_Odds_Ratio_List'\n",
    "        \n",
    "    ])\n",
    "    \n",
    "    return final_df.sort('Combined_Log_Odds_Ratio', descending=True)\n",
    "\n",
    "def preprocess_and_calculate_statistics(enrichment_df: pl.DataFrame) -> Tuple[pl.DataFrame, pl.DataFrame, List[str]]:\n",
    "    \"\"\"\n",
    "    Preprocess data, filter significant entries, and calculate species statistics for all entries.\n",
    "    Also identifies multi-species entries.\n",
    "    \"\"\"\n",
    "    # Replace zero p-values with a very small non-zero value\n",
    "    enrichment_df = enrichment_df.with_columns(\n",
    "        pl.when(pl.col(\"P_Value\") == 0)\n",
    "        .then(np.nextafter(0, 1))\n",
    "        .otherwise(pl.col(\"P_Value\"))\n",
    "        .alias(\"P_Value\")\n",
    "    )\n",
    "    \n",
    "    # Filter for significant entries based on Odds Ratio\n",
    "    significant_entries_df = enrichment_df.filter(pl.col('Odds_Ratio') >= 1)\n",
    "    \n",
    "    # Calculate total species count\n",
    "    total_species_count = significant_entries_df['Taxon_ID'].n_unique()\n",
    "    \n",
    "    # Calculate species counts and percentages for all entries\n",
    "    species_statistics = (\n",
    "        significant_entries_df.group_by('Entry')\n",
    "        .agg([\n",
    "            pl.col('Interpro_ID').first().alias('Interpro_ID'),\n",
    "            pl.col('Taxon_ID').n_unique().alias('Species_Count'),\n",
    "            pl.col('Log_Odds_Ratio').alias('Log_Odds_Ratio_List'),\n",
    "             pl.col('SE_Log_Odds_Ratio').alias('SE_Log_Odds_Ratio_List')\n",
    "        ])\n",
    "        .with_columns(\n",
    "            (pl.col('Species_Count') / total_species_count * 100).alias('Species_Percentage')\n",
    "        )\n",
    "        .sort('Species_Percentage', descending=True)\n",
    "    )\n",
    "        \n",
    "    return significant_entries_df.join(\n",
    "        species_statistics.select([\n",
    "            'Entry',\n",
    "            'Interpro_ID',\n",
    "            'Species_Count', \n",
    "            'Species_Percentage', \n",
    "            'Log_Odds_Ratio_List',\n",
    "            'SE_Log_Odds_Ratio_List' \n",
    "        ]), \n",
    "        on='Entry'\n",
    "    )\n",
    "\n",
    "def random_effects_meta_analysis(interpro_id,\n",
    "                                 log_odds_ratios: Union[List[float], NDArray[np.float64]], \n",
    "                                 se_log_odds_ratios: Union[List[float], NDArray[np.float64]], \n",
    "                                 original_p_value: float,\n",
    "                                 species_count: int,\n",
    "                                 species_percentage: int) -> Dict[str, Union[float, int]]:\n",
    "    \"\"\"\n",
    "    Perform random effects meta-analysis on log odds ratios.\n",
    "    \"\"\"\n",
    "    num_entries = len(log_odds_ratios)\n",
    "    if num_entries <= 1:\n",
    "        return {\n",
    "            'Interpro_ID': interpro_id,\n",
    "            'Combined_Log_Odds_Ratio': log_odds_ratios[0],\n",
    "            'Combined_SE': se_log_odds_ratios[0],\n",
    "#             'Tau_Squared': float('nan'),\n",
    "#             'Q_Statistic': float('nan'),\n",
    "#             'I_Squared': float('nan'),\n",
    "            'P_Value': float(original_p_value),\n",
    "            'Species_Count': species_count,\n",
    "            'Species_Percentage': species_percentage\n",
    "        }\n",
    "    \n",
    "    weights = 1 / np.square(se_log_odds_ratios)\n",
    "    weighted_mean = np.average(log_odds_ratios, weights=weights)\n",
    "    Q_statistic = np.sum(weights * np.square(log_odds_ratios - weighted_mean))\n",
    "    degrees_freedom = len(log_odds_ratios) - 1\n",
    "    C_value = np.sum(weights) - (np.sum(np.square(weights)) / np.sum(weights))\n",
    "    tau_squared = max(0, (Q_statistic - degrees_freedom) / C_value)\n",
    "    random_weights = 1 / (np.square(se_log_odds_ratios) + tau_squared)\n",
    "    combined_mean = np.average(log_odds_ratios, weights=random_weights)\n",
    "    combined_se = np.sqrt(1 / np.sum(random_weights))\n",
    "    z_score = combined_mean / combined_se\n",
    "    \n",
    "    # Use t-distribution to calculate p-value, to better account for the small sizes of samples\n",
    "    p_value = 2 * (1 - t.cdf(abs(z_score), df=num_entries - 1))\n",
    "    return {\n",
    "        'Interpro_ID':interpro_id,\n",
    "        'Combined_Log_Odds_Ratio': float(combined_mean),\n",
    "        'Combined_SE': float(combined_se),\n",
    "        # Uncomment these lines to get heterogeneity data\n",
    "        #'Tau_Squared': float(tau_squared),\n",
    "        #'Q_Statistic': float(Q_statistic),\n",
    "        #'I_Squared': float(max(0, (Q_statistic - degrees_freedom) / Q_statistic * 100) if Q_statistic > 0 else 0),\n",
    "        'P_Value': float(p_value),\n",
    "        'Species_Count': species_count,\n",
    "        'Species_Percentage': species_percentage\n",
    "    }\n",
    "\n",
    "def apply_meta_analysis_and_stats(multi_species_data: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Apply random effects meta-analysis and compute log odds ratio statistics.\n",
    "    \"\"\"\n",
    "    return (\n",
    "        multi_species_data.group_by('Entry')\n",
    "        .agg(\n",
    "            [\n",
    "                pl.col('Interpro_ID').first().alias('Interpro_ID'),\n",
    "                pl.col('Log_Odds_Ratio').alias('Log_Odds_Ratio_List'),\n",
    "                pl.col('SE_Log_Odds_Ratio').alias('SE_Log_Odds_Ratio_List'),\n",
    "                pl.col('P_Value').first().alias('Original_P_Value'),\n",
    "                pl.col('Species_Count').first().alias('Species_Count'),\n",
    "                pl.col('Species_Percentage').first().alias('Species_Percentage')\n",
    "                \n",
    "            ]\n",
    "        )\n",
    "        .with_columns([\n",
    "            pl.struct([\n",
    "                'Interpro_ID',\n",
    "                'Log_Odds_Ratio_List', \n",
    "                'SE_Log_Odds_Ratio_List', \n",
    "                'Original_P_Value',\n",
    "                'Species_Count',\n",
    "                'Species_Percentage'\n",
    "            ]).map_elements(\n",
    "                lambda s: random_effects_meta_analysis(\n",
    "                    s['Interpro_ID'],\n",
    "                    s['Log_Odds_Ratio_List'], \n",
    "                    s['SE_Log_Odds_Ratio_List'],\n",
    "                    s['Original_P_Value'],\n",
    "                    s['Species_Count'],\n",
    "                    s['Species_Percentage']\n",
    "                ),\n",
    "                return_dtype=pl.Struct([\n",
    "                    pl.Field('Interpro_ID', pl.Utf8),\n",
    "                    pl.Field('Combined_Log_Odds_Ratio', pl.Float64),\n",
    "                    pl.Field('Combined_SE', pl.Float64),\n",
    "                    # Uncomment these lines to get heterogeneity data\n",
    "                    #pl.Field('Tau_Squared', pl.Float64),\n",
    "                    #pl.Field('Q_Statistic', pl.Float64),\n",
    "                    #pl.Field('I_Squared', pl.Float64),\n",
    "                    pl.Field('P_Value', pl.Float64),\n",
    "                    pl.Field('Species_Count', pl.Int64),\n",
    "                    pl.Field('Species_Percentage', pl.Float64),\n",
    "                ])\n",
    "            ).alias('Meta_Analysis_Results')\n",
    "        ])\n",
    "    )\n",
    "\n",
    "def unpack_meta_analysis_results(combined_effects_df: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Unpack the Meta_Analysis_Results and Log_Odds_Ratio_Stats structs into separate columns.\n",
    "    \"\"\"\n",
    "    return combined_effects_df.with_columns([\n",
    "        pl.col('Meta_Analysis_Results').struct.field('Interpro_ID'),\n",
    "        pl.col('Meta_Analysis_Results').struct.field('Combined_Log_Odds_Ratio'),\n",
    "        pl.col('Meta_Analysis_Results').struct.field('Combined_SE'),\n",
    "        # Uncomment these lines to get heterogeneity data\n",
    "        #pl.col('Meta_Analysis_Results').struct.field('Tau_Squared'),\n",
    "        #pl.col('Meta_Analysis_Results').struct.field('Q_Statistic'),\n",
    "        #pl.col('Meta_Analysis_Results').struct.field('I_Squared'),\n",
    "        pl.col('Meta_Analysis_Results').struct.field('P_Value'),\n",
    "        pl.col('Meta_Analysis_Results').struct.field('Species_Count'),\n",
    "        pl.col('Meta_Analysis_Results').struct.field('Species_Percentage')        \n",
    "    ]).drop(['Meta_Analysis_Results'])\n",
    "\n",
    "def adjust_p_values(enrichment_summary_df: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Adjust p-values using FDR.\n",
    "    \"\"\"\n",
    "    # Replace zero p-values with a very small non-zero value\n",
    "    enrichment_summary_df = enrichment_summary_df.with_columns(\n",
    "        pl.when(pl.col(\"P_Value\") == 0)\n",
    "        .then(np.nextafter(0, 1))\n",
    "        .otherwise(pl.col(\"P_Value\"))\n",
    "        .alias(\"P_Value\")\n",
    "    )\n",
    "    \n",
    "    # Adjust meta-analysis p-values using FDR (Benjamini-Hochberg method)\n",
    "    meta_p_values = enrichment_summary_df['P_Value'].to_numpy()\n",
    "    _, adjusted_meta_p_values, _, _ = multipletests(meta_p_values, method='fdr_bh', alpha=0.05)\n",
    "    enrichment_summary_df = enrichment_summary_df.with_columns(\n",
    "        pl.Series('Adjusted_Meta_P_Value', adjusted_meta_p_values)\n",
    "    )\n",
    "    \n",
    "# Adds biological interpretation to the statistical data\n",
    "#     # Calculate Odds Ratio, Cohen's d, and Yule's Q\n",
    "#     enrichment_summary_df = enrichment_summary_df.with_columns([\n",
    "#         pl.col('Combined_Log_Odds_Ratio').exp().alias('Odds_Ratio')])\n",
    "    \n",
    "#     enrichment_summary_df = enrichment_summary_df.with_columns([\n",
    "#         (pl.col('Combined_Log_Odds_Ratio') * (np.sqrt(3) / np.pi)).alias('Cohens_d'),\n",
    "#         ((pl.col('Odds_Ratio') - 1) / (pl.col('Odds_Ratio') + 1)).alias('Yules_Q')\n",
    "#     ])\n",
    "    \n",
    "    return enrichment_summary_df.drop(\"Original_P_Value\")\n",
    "\n",
    "# Uncomment these lines to add biological interpretation to the statistical data\n",
    "\n",
    "# def interpret_and_filter_effect_size(enrichment_summary_df):\n",
    "#     \"\"\"\n",
    "#     Apply effect size interpretation to enrichment data and filter significant entries.\n",
    "#     \"\"\"\n",
    "#     def interpret_effect_size(cohens_d, yules_q, odds_ratio):\n",
    "#         if abs(cohens_d) < 0.2 or abs(yules_q) < 0.1 or 0.8 < odds_ratio < 1.25:\n",
    "#             return \"Negligible effect\"\n",
    "#         elif 0.2 <= abs(cohens_d) < 0.5 or 0.1 <= abs(yules_q) < 0.3 or 0.5 < odds_ratio <= 0.8 or 1.25 <= odds_ratio < 2:\n",
    "#             return \"Small effect\"\n",
    "#         elif 0.5 <= abs(cohens_d) < 0.8 or 0.3 <= abs(yules_q) < 0.5 or 0.33 < odds_ratio <= 0.5 or 2 <= odds_ratio < 3:\n",
    "#             return \"Medium effect\"\n",
    "#         else:\n",
    "#             return \"Large effect\"\n",
    "    \n",
    "#     enrichment_summary_df = enrichment_summary_df.with_columns(\n",
    "#         pl.struct(['Cohens_d', 'Yules_Q', 'Odds_Ratio']).map_elements(\n",
    "#             lambda s: interpret_effect_size(s['Cohens_d'], s['Yules_Q'], s['Odds_Ratio']),\n",
    "#             return_dtype=pl.Utf8\n",
    "#         ).alias('Effect_Size_Interpretation')\n",
    "#     )\n",
    "    \n",
    "#     # Filter significant entries based on adjusted meta-analysis p-values\n",
    "#     significant_enrichment_df = enrichment_summary_df.filter(\n",
    "#         (pl.col('Adjusted_Meta_P_Value') < 0.05)\n",
    "#     ).sort('Odds_Ratio', descending=True)\n",
    "    \n",
    "#     # Convert Log Odds Ratio IQR to Odds Ratio IQR\n",
    "#     significant_enrichment_df = significant_enrichment_df.with_columns(\n",
    "#         (significant_enrichment_df['Log_Odds_Ratio_IQR'].exp()).alias('Odds_Ratio_IQR')\n",
    "#     )\n",
    "    \n",
    "#     return significant_enrichment_df\n",
    "\n",
    "def process_enrichment_results(enrichment_df: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Main processing function that handles both single-taxon and multi-taxon cases.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check if DataFrame is empty\n",
    "    if enrichment_df.is_empty():\n",
    "        return pl.DataFrame({\n",
    "            'Entry': ['No significant entries'],\n",
    "            'Interpro_ID': ['IPR000000'],\n",
    "            'Species_Count': [0],\n",
    "            'Species_Percentage': [0.0],\n",
    "            'Combined_Log_Odds_Ratio': [0.0],\n",
    "            'Combined_SE': [0.0],\n",
    "            'P_Value': [1.0],\n",
    "            'Adjusted_Meta_P_Value': [1.0],\n",
    "            'Log_Odds_Ratio_List': [[0.0]],  # List with a single value\n",
    "            'SE_Log_Odds_Ratio_List': [[0.0]]  # List with a single value\n",
    "            })\n",
    "        \n",
    "    # Check taxon count\n",
    "    has_one_taxon_id = check_taxon_count(enrichment_df)\n",
    "    \n",
    "    if has_one_taxon_id:\n",
    "        significant_enrichment_df = process_single_taxon_data(enrichment_df)\n",
    "        \n",
    "        # Process single-taxon data with percentage but without random effects\n",
    "        return significant_enrichment_df\n",
    "    \n",
    "    else :\n",
    "        significant_entries_df = preprocess_and_calculate_statistics(enrichment_df)\n",
    "\n",
    "        combined_effects_df = apply_meta_analysis_and_stats(significant_entries_df)\n",
    "\n",
    "        combined_effects_df = unpack_meta_analysis_results(combined_effects_df)\n",
    "       \n",
    "        if combined_effects_df.is_empty():\n",
    "            return pl.DataFrame({\n",
    "                'Entry': ['No significant entries'],\n",
    "                'Interpro_ID': ['IPR000000'],\n",
    "                'Species_Count': [0],\n",
    "                'Species_Percentage': [0.0],\n",
    "                'Combined_Log_Odds_Ratio': [0.0],\n",
    "                'Combined_SE': [0.0],\n",
    "                'P_Value': [1.0],\n",
    "                'Adjusted_Meta_P_Value': [1.0],\n",
    "                'Log_Odds_Ratio_List': [[0.0]], \n",
    "                'SE_Log_Odds_Ratio_List': [[0.0]] \n",
    "            })\n",
    " \n",
    "        enrichment_summary_df = adjust_p_values(combined_effects_df)\n",
    "# Uncomment for interpretation\n",
    "#         significant_enrichment_df = interpret_and_filter_effect_size(enrichment_summary_df)\n",
    "\n",
    "        # Select and reorder columns for the final summary\n",
    "        significant_enrichment_df = (\n",
    "            enrichment_summary_df\n",
    "            .sort('Species_Percentage', descending=True)\n",
    "            .select([\n",
    "                'Entry',\n",
    "                'Interpro_ID',\n",
    "                'Species_Count',\n",
    "                'Species_Percentage',\n",
    "                'Combined_Log_Odds_Ratio',\n",
    "                'Combined_SE',\n",
    "#                 'Cohens_d',\n",
    "#                 'Yules_Q',\n",
    "#                 'Tau_Squared',\n",
    "#                 'Q_Statistic',\n",
    "#                 'I_Squared',\n",
    "                'P_Value',\n",
    "                'Adjusted_Meta_P_Value',\n",
    "                'Log_Odds_Ratio_List',\n",
    "                'SE_Log_Odds_Ratio_List'\n",
    "            ])\n",
    "        )\n",
    "\n",
    "        return significant_enrichment_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e17e5f6-43cc-4952-876e-dab252c1fb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "go_categories = [\"biological_process\", \"molecular_function\", \"cellular_component\"]\n",
    "default_columns = [\n",
    "    \"Entry\",\n",
    "    'Interpro_ID',\n",
    "    \"Description\", \n",
    "    \"Class\",\n",
    "    \"Species_Count\",\n",
    "    \"Species_Percentage\",\n",
    "    \"Combined_Log_Odds_Ratio\",\n",
    "    \"Combined_SE\",\n",
    "    \"P_Value\",\n",
    "    \"Adjusted_Meta_P_Value\",\n",
    "    \"Log_Odds_Ratio_List\",\n",
    "    \"SE_Log_Odds_Ratio_List\"\n",
    "]\n",
    "\n",
    "schema = {\n",
    "    \"Entry\": pl.Utf8,\n",
    "    'Interpro_ID': pl.Utf8,\n",
    "    \"Description\": pl.Utf8,\n",
    "    \"Class\": pl.Utf8,\n",
    "    \"Species_Count\": pl.Int64, \n",
    "    \"Species_Percentage\": pl.Float64,\n",
    "    \"Combined_Log_Odds_Ratio\": pl.Float64,\n",
    "    \"Combined_SE\": pl.Float64,\n",
    "    \"P_Value\": pl.Float64,\n",
    "    \"Adjusted_Meta_P_Value\": pl.Float64,\n",
    "    \"Log_Odds_Ratio_List\": pl.List(pl.Float64),\n",
    "    \"SE_Log_Odds_Ratio_List\": pl.List(pl.Float64)\n",
    "}\n",
    "\n",
    "default_row = {\n",
    "    \"Entry\": \"GO:0000000\",\n",
    "    \"Interpro_ID\": \"IPR000000\",\n",
    "    \"Description\": \"No significant terms found\",\n",
    "    \"Species_Count\": 0,\n",
    "    \"Species_Percentage\": 0.0,\n",
    "    \"Combined_Log_Odds_Ratio\": 0.0,\n",
    "    \"Combined_SE\": 0.0,\n",
    "    \"P_Value\": 1.0,\n",
    "    \"Adjusted_Meta_P_Value\": 1.0,\n",
    "    \"Log_Odds_Ratio_List\": [0.0],\n",
    "    \"SE_Log_Odds_Ratio_List\": [0.0]\n",
    "}\n",
    "\n",
    "column_mapping = {\n",
    "    \"GO_term\": \"Entry\",\n",
    "    \"P_value\": \"P_Value\",\n",
    "    \"Odds_ratio\": \"Odds_Ratio\",\n",
    "    \"Log_odds_ratio\": \"Log_Odds_Ratio\",\n",
    "    \"SE_log_odds_ratio\": \"SE_Log_Odds_Ratio\"\n",
    "}\n",
    "\n",
    "def create_empty_df(category: Optional[str] = None) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Creates an empty DataFrame with default values.\n",
    "    If category is provided, creates single row for that category.\n",
    "    If not, creates rows for all categories.\n",
    "    \"\"\"\n",
    "    categories = [category] if category else go_categories\n",
    "    rows = []\n",
    "    \n",
    "    for cat in categories:\n",
    "        row = default_row.copy()\n",
    "        row[\"Class\"] = cat\n",
    "        rows.append(row)\n",
    "    \n",
    "    return pl.DataFrame(rows,schema=schema).select(default_columns)\n",
    "\n",
    "def capitalize_first_letter(text: str) -> str:\n",
    "    \"\"\"Capitalizes the first letter of a string if it exists.\"\"\"\n",
    "    if isinstance(text, str) and text:\n",
    "        return text[0].upper() + text[1:]\n",
    "    return text\n",
    "\n",
    "def process_goea_results(goea_df: pl.DataFrame, phylum_name: str) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Processes Gene Ontology Enrichment Analysis (GOEA) results from multiple species per unique Phylum.\n",
    "    Handles missing categories by adding empty rows with correct category labels.\n",
    "    \"\"\"\n",
    "    if goea_df.is_empty():\n",
    "        return create_empty_df()\n",
    "\n",
    "    \n",
    "    goea_df = goea_df.with_columns(\n",
    "        pl.lit(\"IPR000000\").alias(\"Interpro_ID\")\n",
    "    )\n",
    "    # Preprocess the input DataFrame\n",
    "    processed_df = (\n",
    "        goea_df\n",
    "        .with_columns([\n",
    "            # Handle zero p-values\n",
    "            pl.when(pl.col(\"P_value\") == 0)\n",
    "            .then(np.nextafter(0,1))\n",
    "            .otherwise(pl.col(\"P_value\"))\n",
    "            .alias(\"P_value\"),\n",
    "            # Capitalize descriptions\n",
    "            pl.col(\"Description\")\n",
    "            .map_elements(capitalize_first_letter, return_dtype=pl.Utf8)\n",
    "            .alias(\"Description\")\n",
    "        ])\n",
    "        .sort(\"P_value\")\n",
    "    )\n",
    "    \n",
    "    # Create entry-description mapping\n",
    "    entry_description_mapping = (\n",
    "        processed_df\n",
    "        .select([\"GO_term\", \"Description\", 'Interpro_ID'])\n",
    "        .unique()\n",
    "        .rename({\"GO_term\": \"Entry\"})\n",
    "    )\n",
    "    \n",
    "    processed_categories: Dict[str, pl.DataFrame] = {}\n",
    "    \n",
    "    for category in go_categories:\n",
    "        try:\n",
    "            category_df = processed_df.filter(pl.col(\"Class\") == category)\n",
    "            \n",
    "            if category_df.is_empty():\n",
    "                processed_categories[category] = create_empty_df(category)\n",
    "                continue\n",
    "            \n",
    "            # Process the category\n",
    "            enrichment_df = process_enrichment_results(\n",
    "                category_df.rename(column_mapping)\n",
    "            )\n",
    "            \n",
    "            if enrichment_df.is_empty():\n",
    "                processed_categories[category] = create_empty_df(category)\n",
    "                continue\n",
    "            \n",
    "            # Merge with descriptions and ensure all required columns\n",
    "            processed_categories[category] = (\n",
    "                enrichment_df\n",
    "                .join(entry_description_mapping, on=\"Entry\", how=\"left\")\n",
    "                .with_columns([\n",
    "                    pl.col(\"Description\").fill_null(\"No description available\"),\n",
    "                    pl.lit(category).alias(\"Class\")\n",
    "                ])\n",
    "                .select(default_columns).cast(schema)\n",
    "            )\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {category} for phylum {phylum_name}: {str(e)}\")\n",
    "            processed_categories[category] = create_empty_df(category)\n",
    "    \n",
    "    # Combine all categories\n",
    "    try:\n",
    "        significant_go_terms = pl.concat(\n",
    "            [df for df in processed_categories.values()],\n",
    "            how=\"vertical\"\n",
    "        )\n",
    "        \n",
    "        return (significant_go_terms if not significant_go_terms.is_empty() \n",
    "                else create_empty_df())\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error combining results for phylum {phylum_name}: {str(e)}\")\n",
    "        return create_empty_df()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03b2b22-fe0f-46b3-9d4a-fe610ab547fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store results\n",
    "enrichment_results_by_phylum = {}\n",
    "\n",
    "# Read each file from the families, domains enrichment results directories, and gene ontology results\n",
    "enrichment_types_dirs = {\n",
    "    \"families\": entry_results_dir.get(\"families\"),\n",
    "    \"domains\": entry_results_dir.get(\"domains\"),\n",
    "    \"gene_ontology\": msgoea_results_dir\n",
    "}\n",
    "\n",
    "# Iterate through all directories and files\n",
    "for enrichment_type, dir_path in enrichment_types_dirs.items():\n",
    "    if enrichment_type in [\"families\", \"domains\"]:\n",
    "        for file_path in dir_path.glob(\"*_enrichment_results.txt\"):\n",
    "            # Get the filename from the file path\n",
    "            file_name = file_path.name\n",
    "\n",
    "            # Extract phylum name from filename by splitting on the appropriate enrichment type\n",
    "            phylum_name = file_name.split(f\"_{enrichment_type}\")[0]\n",
    "\n",
    "            # Load the enrichment data into a Polars DataFrame\n",
    "            enrichment_df = pl.read_csv(file_path, separator=\"\\t\")\n",
    "\n",
    "            # Process the enrichment results using the functions provided\n",
    "            significant_enrichment_df = process_enrichment_results(enrichment_df)\n",
    "\n",
    "            # Save the significant results DataFrame regardless of whether it's empty\n",
    "            output_filename = f\"{phylum_name}_{enrichment_type}_combined_significant_enrichment_results.parquet\"\n",
    "            output_path = output_dirs[f\"combined_{enrichment_type}\"] / output_filename\n",
    "            significant_enrichment_df.write_parquet(output_path)\n",
    "\n",
    "            # Store the processed DataFrame in the dictionary with the phylum name as the key\n",
    "            if phylum_name not in enrichment_results_by_phylum:\n",
    "                enrichment_results_by_phylum[phylum_name] = {}\n",
    "\n",
    "            # Store the results based on enrichment type (domains or families)\n",
    "            enrichment_results_by_phylum[phylum_name][enrichment_type] = significant_enrichment_df\n",
    "\n",
    "    elif enrichment_type == \"gene_ontology\":\n",
    "        # Get all files in directory and group by phylum\n",
    "        phylum_files = {}\n",
    "        for file in os.listdir(dir_path):\n",
    "            if file.endswith(\"_results.txt\"):\n",
    "                # Extract phylum name (everything before *multi or *empty)\n",
    "                phylum_name = file.split('_multi')[0].split('_empty')[0]\n",
    "                if phylum_name not in phylum_files:\n",
    "                    phylum_files[phylum_name] = {'multi': None, 'empty': None}\n",
    "                if '_multi_species_goea_results.txt' in file:\n",
    "                    phylum_files[phylum_name]['multi'] = file\n",
    "                elif '_empty_results.txt' in file:\n",
    "                    phylum_files[phylum_name]['empty'] = file\n",
    "\n",
    "        # Process each phylum for gene ontology results\n",
    "        for phylum_name, files_dict in phylum_files.items():\n",
    "            try:\n",
    "                # Ensure the phylum exists in the results dictionary without overwriting previous data\n",
    "                if phylum_name not in enrichment_results_by_phylum:\n",
    "                    enrichment_results_by_phylum[phylum_name] = {}\n",
    "\n",
    "                # Add or update the gene_ontology_results key for this phylum\n",
    "                enrichment_results_by_phylum[phylum_name].update({\"gene_ontology_results\": None})\n",
    "\n",
    "                if files_dict['multi'] is not None:\n",
    "                    # Load and process multi-species results\n",
    "                    file_path = dir_path / files_dict['multi']\n",
    "                    try:\n",
    "                        enrichment_df = pl.read_csv(file_path, separator=\"\\t\")\n",
    "                        significant_go_df = process_goea_results(enrichment_df, phylum_name)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing multi-species results for {phylum_name}: {str(e)}\")\n",
    "                        significant_go_df = create_empty_df()\n",
    "                else:\n",
    "                    # Create empty DataFrame for empty results or missing files\n",
    "                    significant_go_df = create_empty_df()\n",
    "                    if not files_dict['empty']:\n",
    "                        print(f\"Warning: No results file found for {phylum_name}\")\n",
    "\n",
    "                # Save results\n",
    "                output_filename = f\"{phylum_name}_combined_significant_go_terms.parquet\"\n",
    "                output_path = output_dirs[\"combined_go_terms\"] / output_filename\n",
    "                significant_go_df.write_parquet(output_path)\n",
    "\n",
    "                # Store in results dictionary\n",
    "                enrichment_results_by_phylum[phylum_name][\"gene_ontology_results\"] = significant_go_df\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error handling phylum {phylum_name}: {str(e)}\")\n",
    "                # Ensure we still have an entry with empty results if an error occurs\n",
    "                if phylum_name not in enrichment_results_by_phylum:\n",
    "                    enrichment_results_by_phylum[phylum_name] = {}\n",
    "                enrichment_results_by_phylum[phylum_name][\"gene_ontology_results\"] = create_empty_df()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

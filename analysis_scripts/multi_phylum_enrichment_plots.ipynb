{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84f5c5a-2df0-48b2-9bdb-6ed1c87593fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, glob, pathlib, asyncio, aiohttp, nest_asyncio, shutil, pickle\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import pandas as pd \n",
    "from typing import *\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.typing import NDArray\n",
    "from matplotlib.ticker import FixedLocator\n",
    "from matplotlib.colors import Normalize, ListedColormap\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.cm as cm\n",
    "from goatools.obo_parser import GODag\n",
    "from goatools.semsim.termwise.wang import SsWang\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "from scipy.spatial.distance import squareform\n",
    "\n",
    "# Apply nest_asyncio to allow nested event loops in Jupyter\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Set the style for seaborn plots\n",
    "sns.set_style(\"ticks\",{'font.family':'serif', 'font.serif':'Microsoft Sans Serif'})\n",
    "plt.style.use('seaborn-v0_8-ticks')\n",
    "sns.set_context(\"paper\",font_scale=2)\n",
    "\n",
    "# Set up a dictionary to store the various colormaps that will be used later for the size- and color-encoded heatmaps\n",
    "colormaps={\n",
    "    'biological_process': sns.cubehelix_palette(start=0, rot=0.3, dark=0.2, light=0.93, gamma=1.5, as_cmap=True),\n",
    "    'molecular_function': sns.cubehelix_palette(start=1, rot=0.1, dark=0.1, light=0.93, gamma=1.5, as_cmap=True),\n",
    "    'cellular_component': sns.cubehelix_palette(start=2, rot=0.3, dark=0.2, light=0.93, gamma=1.7, as_cmap=True),\n",
    "    'domains': sns.cubehelix_palette(start=3, rot=0.6, dark=0.1, light=0.9, gamma=1.3, as_cmap=True),\n",
    "    'families': sns.cubehelix_palette(start=0, rot=0, dark=0.0, light=0.88, gamma=1.3, as_cmap=True),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d665ead4-5e0b-44e7-988b-8716dff96ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base directory for data storage\n",
    "mspeea_results_dir = pathlib.Path(\"/storage/group/izg5139/default/lefteris/multi_species_entry_enrichment_files/multi_species_entry_enrichment_results\")\n",
    "msgoea_results_dir = pathlib.Path(\"/storage/group/izg5139/default/lefteris/multi_species_goea_files/multi_species_goea_results\")\n",
    "\n",
    "combined_enrichment_dirs = {\n",
    "    \"combined_domains\": mspeea_results_dir / 'combined_domain_enrichment_results',\n",
    "    \"combined_families\": mspeea_results_dir / 'combined_family_enrichment_results',\n",
    "    \"combined_go_terms\": msgoea_results_dir / 'combined_gene_ontology_results'\n",
    "}\n",
    "\n",
    "# File patterns for each type\n",
    "patterns = {\n",
    "    \"domains\": \"_domains_combined_significant_enrichment_results.parquet\",\n",
    "    \"families\": \"_families_combined_significant_enrichment_results.parquet\",\n",
    "    \"go_terms\": \"_combined_significant_go_terms.parquet\"\n",
    "}\n",
    "\n",
    "# Create a directory to save the plots\n",
    "plots = pathlib.Path(\"plots\")\n",
    "plots.mkdir(exist_ok=True)\n",
    "\n",
    "# Load GO DAG\n",
    "godag = GODag('/storage/group/izg5139/default/lefteris/multi_species_goea_files/go-basic.obo', optional_attrs={'relationship'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39b8d33-2ee6-44c9-bcc4-792894d7717e",
   "metadata": {},
   "outputs": [],
   "source": [
    "go_term_mapping = {\n",
    "    \"Beta-ureidopropionase activity\": \"Beta-ureidopropionase\",\n",
    "    \"Pyruvate dehydrogenase kinase activity\": \"Pyruvate dehydrogenase kinase\",\n",
    "    \"Ligase activity\": \"Ligase\",\n",
    "    \"TRNA-N1)-methyltransferase activity\": \"tRNA N1-methyltransferase\",\n",
    "    \"Hydroxymethylpyrimidine kinase activity\": \"HMP-kinase\",\n",
    "    \"1,4-alpha-oligoglucan phosphorylase activity\": \"Oligoglucan phosphorylase\",\n",
    "    \"Iron-sulfur cluster binding\": \"Fe-S cluster binding\",\n",
    "    \"Methyltransferase activity\": \"Methyltransferase\",\n",
    "    \"Hydrolase activity, acting on glycosyl bonds\": \"Glycosyl hydrolase\",\n",
    "    \"Threonine-phosphate decarboxylase activity\": \"Threonine decarboxylase\",\n",
    "    \"Magnesium chelatase activity\": \"Magnesium chelatase\",\n",
    "    \"Sequence-specific DNA binding\": \"DNA binding (specific)\",\n",
    "    \"Ribonucleoside-triphosphate reductase activity\": \"rNTP reductase\",\n",
    "    \"Epoxyqueuosine reductase activity\": \"Epoxyqueuosine reductase\",\n",
    "    \"Proline-tRNA ligase activity\": \"Proline-tRNA ligase\",\n",
    "    \"4 iron, 4 sulfur cluster binding\": \"4Fe-4S cluster binding\",\n",
    "    \"Aminoacyl-tRNA ligase activity\": \"Aminoacyl-tRNA ligase\",\n",
    "    \"Oxidoreductase activity\": \"Oxidoreductase\",\n",
    "    \"Acyltransferase activity, transferring groups other than amino-acyl groups\": \"Non-amino acyltransferase\",\n",
    "    \"Dopamine beta-monooxygenase activity\": \"Dopamine monooxygenase\",\n",
    "    \"Mitochondrion targeting sequence binding\": \"Mitochondrial sequence binding\",\n",
    "    \"ABC-type ferric iron transporter activity\": \"Ferric iron transporter\",\n",
    "    \"AMPylase activity\": \"AMPylase\",\n",
    "    \"Cysteine-type exopeptidase activity\": \"Cysteine exopeptidase\",\n",
    "    \"Phosphoribosylglycinamide formyltransferase 2 activity\": \"GAR transformylase 2\",\n",
    "    \"DCTP deaminase activity\": \"dCTP deaminase\",\n",
    "    \"Glycosyltransferase activity\": \"Glycosyltransferase\",\n",
    "    \"Starch synthase activity\": \"Starch synthase\",\n",
    "    \"Exoribonuclease II activity\": \"Exoribonuclease II\",\n",
    "    \"Glucose 6-phosphate:phosphate antiporter activity\": \"Glucose-phosphate antiporter\",\n",
    "    \"Transmembrane transporter activity\": \"Transmembrane transporter\",\n",
    "    \"G protein-coupled serotonin receptor activity\": \"Serotonin GPCR\",\n",
    "    \"Clathrin binding\": \"Clathrin binding\",\n",
    "    \"Ephrin receptor binding\": \"Ephrin receptor binding\",\n",
    "    \"ATP-dependent peptidase activity\": \"ATP-dependent peptidase\",\n",
    "    \"Hsp70 protein binding\": \"Hsp70 binding\",\n",
    "    \"Diacylglycerol-dependent serine/threonine kinase activity\": \"Diacylglycerol Ser/Thr kinase\",\n",
    "    \"First spliceosomal transesterification activity\": \"Spliceosomal transesterification\",\n",
    "    \"Dihydrofolate synthase activity\": \"Dihydrofolate synthase\",\n",
    "    \"S-glutathione dehydrogenase [NAD+] activity\": \"S-glutathione dehydrogenase\",\n",
    "    \"Myosin phosphatase activity\": \"Myosin phosphatase\",\n",
    "    \"GTPase activity\": \"GTPase\",\n",
    "    \"GTP binding\": \"GTP binding\",\n",
    "    \"Protein phosphatase regulator activity\": \"Phosphatase regulator\",\n",
    "    \"Metal ion binding\": \"Metal ion binding\",\n",
    "    \"Ubiquitin-protein transferase activity\": \"Ubiquitin transferase\",\n",
    "    \"Monoatomic ion channel activity\": \"Ion channel\",\n",
    "    \"Estrogen response element binding\": \"Estrogen response binding\",\n",
    "    \"RNA 7-methylguanosine cap binding\": \"RNA cap binding\",\n",
    "    \"Dynein light intermediate chain binding\": \"Dynein binding\",\n",
    "    \"Hydrolase activity, hydrolyzing O-glycosyl compounds\": \"O-glycosyl hydrolase\",\n",
    "    \"Extracellular matrix binding\": \"ECM binding\",\n",
    "    \"Potassium channel activity\": \"Potassium channel\",\n",
    "    \"Extracellular ligand-gated monoatomic ion channel activity\": \"Ligand-gated ion channel\",\n",
    "    \"Squalene synthase activity\": \"Squalene synthase\",\n",
    "    \"N-acetylmuramoyl-L-alanine amidase activity\": \"NAM-L-Ala amidase\",\n",
    "    \"NADH dehydrogenase activity\": \"NADH dehydrogenase\",\n",
    "    \"RNA polymerase II activity\": \"RNA polymerase II\",\n",
    "    \"SnRNA binding\": \"snRNA binding\",\n",
    "    \"Cellulose synthase activity\": \"Cellulose synthase\",\n",
    "    \"UDP-glucose 6-dehydrogenase activity\": \"UDP-glucose dehydrogenase\",\n",
    "    \"O-acetyltransferase activity\": \"O-acetyltransferase\",\n",
    "    \"G protein-coupled receptor activity\": \"GPCR\",\n",
    "    \"Serine-type endopeptidase activity\": \"Serine endopeptidase\",\n",
    "    \"Trehalose biosynthetic process\": \"Trehalose biosynthesis\",\n",
    "    \"L-serine biosynthetic process\": \"L-serine biosynthesis\",\n",
    "    \"Receptor guanylyl cyclase signaling pathway\": \"Guanylyl cyclase signaling\",\n",
    "    \"L-lysine catabolic process to acetyl-CoA via saccharopine\": \"L-lysine catabolism (acetyl-CoA)\",\n",
    "    \"Alternative mRNA splicing, via spliceosome\": \"Alternative mRNA splicing\",\n",
    "    \"TRNA acetylation\": \"tRNA acetylation\",\n",
    "    \"Respiratory electron transport chain\": \"Electron transport chain\",\n",
    "    \"Lipopolysaccharide transport\": \"LPS transport\",\n",
    "    \"Peptidyl-histidine phosphorylation\": \"p-Histidine phosphorylation\",\n",
    "    \"Prenylcysteine catabolic process\": \"Prenylcysteine catabolism\",\n",
    "    \"Nucleotide-excision repair\": \"Nucleotide excision repair\",\n",
    "    \"2'-deoxyribonucleotide biosynthetic process\": \"Deoxyribonucleotide biosynthesis\",\n",
    "    \"Cysteinyl-tRNA aminoacylation\": \"Cysteinyl-tRNA aminoacylation\",\n",
    "    \"RNA catabolic process\": \"RNA catabolism\",\n",
    "    \"Sulfur compound biosynthetic process\": \"Sulfur biosynthesis\",\n",
    "    \"DNA conformation change\": \"DNA conformation change\",\n",
    "    \"Transmembrane transport\": \"Transmembrane transport\",\n",
    "    \"Methylation\": \"Methylation\",\n",
    "    \"Interstrand cross-link repair\": \"Cross-link repair\",\n",
    "    \"Phosphorus metabolic process\": \"Phosphorus metabolism\",\n",
    "    \"Transcription initiation at RNA polymerase II promoter\": \"RNA pol II transcription initiation\",\n",
    "    \"DTDP-rhamnose biosynthetic process\": \"DTDP-rhamnose biosynthesis\",\n",
    "    \"Extracellular polysaccharide biosynthetic process\": \"Polysaccharide biosynthesis\",\n",
    "    \"Phosphate ion transmembrane transport\": \"Phosphate ion transport\",\n",
    "    \"S-adenosylhomocysteine metabolic process\": \"SAH metabolism\",\n",
    "    \"Small molecule metabolic process\": \"Small molecule metabolism\",\n",
    "    \"'de novo' IMP biosynthetic process\": \"de novo IMP biosynthesis\",\n",
    "    \"Acetyl-CoA biosynthetic process\": \"Acetyl-CoA biosynthesis\",\n",
    "    \"Glucose-6-phosphate transport\": \"G-6P transport\",\n",
    "    \"Cell differentiation\": \"Cell differentiation\",\n",
    "    \"Cell surface receptor protein tyrosine kinase signaling pathway\": \"Receptor tyrosine kinase signaling\",\n",
    "    \"Phosphorylation\": \"Phosphorylation\",\n",
    "    \"Intracellular signal transduction\": \"Intracellular signaling\",\n",
    "    \"Protein refolding\": \"Protein refolding\",\n",
    "    \"Mitotic DNA replication preinitiation complex assembly\": \"DNA replication preinitiation complex\",\n",
    "    \"SiRNA processing\": \"siRNA processing\",\n",
    "    \"Dihydrofolate biosynthetic process\": \"Dihydrofolate biosynthesis\",\n",
    "    \"Protein stabilization\": \"Protein stabilization\",\n",
    "    \"Cellular response to heat\": \"Heat response\",\n",
    "    \"Microtubule-based process\": \"Microtubule process\",\n",
    "    \"Phosphatidylinositol dephosphorylation\": \"PI dephosphorylation\",\n",
    "    \"DNA repair\": \"DNA repair\",\n",
    "    \"Estrogen receptor signaling pathway\": \"Estrogen signaling\",\n",
    "    \"Monoatomic cation transmembrane transport\": \"Cation transport\",\n",
    "    \"Intraciliary retrograde transport\": \"Ciliary retrograde transport\",\n",
    "    \"Protein polyglycylation\": \"Protein glycine modification\",\n",
    "    \"Phospholipase C-activating G protein-coupled receptor signaling pathway\": \"PLC-activating GPCR signaling\",\n",
    "    \"Release of sequestered calcium ion into cytosol by sarcoplasmic reticulum\": \"SR Ca\\u00B2\\u207A release\",\n",
    "    \"Stabilization of membrane potential\": \"Membrane potential stabilization\",\n",
    "    \"Farnesyl diphosphate metabolic process\": \"Farnesyl diphosphate metabolism\",\n",
    "    \"Cellular response to nutrient levels\": \"Nutrient response\",\n",
    "    \"U5 snRNA 3'-end processing\": \"U5 snRNA processing\",\n",
    "    \"Monoatomic ion transmembrane transport\": \"Ion transport\",\n",
    "    \"Cellulose biosynthetic process\": \"Cellulose biosynthesis\",\n",
    "    \"Amino acid transport\": \"Amino acid transport\",\n",
    "    \"Auxin-activated signaling pathway\": \"Auxin signaling\",\n",
    "    \"Regulation of membrane potential\": \"Membrane potential regulation\",\n",
    "    \"G protein-coupled receptor signaling pathway\": \"GPCR signaling\",\n",
    "    \"PAS complex\": \"PAS complex\",\n",
    "    \"Sec62/Sec63 complex\": \"Sec62/63 complex\",\n",
    "    \"Delta DNA polymerase complex\": \"Delta polymerase complex\",\n",
    "    \"Chromosome, telomeric region\": \"Telomeric region\",\n",
    "    \"DNA helicase complex\": \"DNA helicase complex\",\n",
    "    \"Excinuclease repair complex\": \"Excinuclease repair complex\",\n",
    "    \"Ribonuclease H2 complex\": \"RNase H2 complex\",\n",
    "    \"External side of plasma membrane\": \"Plasma membrane (external side)\",\n",
    "    \"Cytochrome complex\": \"Cytochrome complex\",\n",
    "    \"Cytoskeleton\": \"Cytoskeleton\",\n",
    "    \"Thylakoid\": \"Thylakoid\",\n",
    "    \"Protein-containing complex\": \"Protein complex\",\n",
    "    \"Cytosol\": \"Cytosol\",\n",
    "    \"F-actin capping protein complex\": \"F-actin capping complex\",\n",
    "    \"Postsynapse\": \"Postsynapse\",\n",
    "    \"Synaptic vesicle\": \"Synaptic vesicle\",\n",
    "    \"Nuclear RNA-directed RNA polymerase complex\": \"Nuclear RNA pol complex\",\n",
    "    \"Axonemal microtubule\": \"Axonemal microtubule\",\n",
    "    \"Hrd1p ubiquitin ligase ERAD-L complex\": \"Hrd1p ERAD-L complex\",\n",
    "    \"Perinuclear region of cytoplasm\": \"Perinuclear cytoplasm\",\n",
    "    \"Microtubule\": \"Microtubule\",\n",
    "    \"Protein phosphatase type 2A complex\": \"PP2A complex\",\n",
    "    \"Membrane\": \"Membrane\",\n",
    "    \"Transcription factor TFIIH core complex\": \"TFIIH core complex\",\n",
    "    \"Cul4A-RING E3 ubiquitin ligase complex\": \"Cul4A-RING complex\",\n",
    "    \"Cytoskeleton of presynaptic active zone\": \"Presynaptic cytoskeleton\",\n",
    "    \"Non-motile cilium\": \"Non-motile cilium\",\n",
    "    \"Intracellular membrane-bounded organelle\": \"Intracellular organelle\",\n",
    "    \"Cytoplasm\": \"Cytoplasm\",\n",
    "    \"Spectrin\": \"Spectrin\",\n",
    "    \"Gap junction\": \"Gap junction\",\n",
    "    \"Transcription regulator complex\": \"Transcription regulator\",\n",
    "    \"Nuclear lamina\": \"Nuclear lamina\",\n",
    "    \"RNA polymerase II, core complex\": \"RNA pol II core complex\",\n",
    "    \"Apoplast\": \"Apoplast\",\n",
    "    \"Golgi apparatus\": \"Golgi apparatus\",\n",
    "    \"Golgi membrane\": \"Golgi membrane\",\n",
    "    \"Receptor complex\": \"Receptor complex\",\n",
    "    \"Extracellular region\": \"Extracellular region\",\n",
    "    \"Plasma membrane\": \"Plasma membrane\",\n",
    "    \"DNA replication initiation\": \"DNA initiation\",\n",
    "    \"[2Fe-2S] cluster assembly\": \"2Fe-2S assembly\",\n",
    "    \"Regulation of DNA-templated transcription initiation\": \"Transcription initiation regulation\",\n",
    "    \"Purine nucleotide biosynthetic process\": \"Purine biosynthesis\",\n",
    "    \"Protein phosphorylation\": \"Protein phosphorylation\",\n",
    "    \"Polysaccharide catabolic process\": \"Polysaccharide catabolism\",\n",
    "    \"Aerobic respiration\": \"Aerobic respiration\",\n",
    "    \"Regulation of transcription by RNA polymerase II\": \"Transcription regulation (RNA pol II)\",\n",
    "    \"Signal transduction\": \"Signal transduction\",\n",
    "    \"Protein deubiquitination\": \"Protein deubiquitination\",\n",
    "    \"Box C/D sno(s)RNA 3'-end processing\": \"Box C/D snoRNA processing\",\n",
    "    \"Carotenoid biosynthetic process\": \"Carotenoid biosynthesis\",\n",
    "    \"DGTP catabolic process\": \"dGTP catabolism\",\n",
    "    \"Regulation of DNA-templated transcription\": \"Transcription regulation\",\n",
    "    \"Carbohydrate derivative metabolic process\": \"Carbohydrate derivative metabolism\",\n",
    "    \"Lipid metabolic process\": \"Lipid metabolism\",\n",
    "    \"Prenylated protein catabolic process\": \"Prenylated protein catabolism\",\n",
    "    \"Valyl-tRNA aminoacylation\": \"Valyl-tRNA synthesis\",\n",
    "    \"Positive regulation of transcription by RNA polymerase II\": \"Pos. transcription reg. (RNA pol II)\",\n",
    "    \"Proteolysis\": \"Proteolysis\",\n",
    "    \"Carbohydrate metabolic process\": \"Carbohydrate metabolism\",\n",
    "    \"Cell wall organization\": \"Cell wall organization\",\n",
    "    \"Peptide transport\": \"Peptide transport\",\n",
    "    \"Chromatin remodeling\": \"Chromatin remodeling\",\n",
    "    \"Synapse\": \"Synapse\",\n",
    "    \"Ubiquitin ligase complex\": \"Ubiquitin ligase complex\",\n",
    "    \"Lateral plasma membrane\": \"Lateral membrane\",\n",
    "    \"Cytoplasmic vesicle\": \"Cytoplasmic vesicle\",\n",
    "    \"Glycine cleavage complex\": \"Glycine cleavage complex\",\n",
    "    \"Outer membrane\": \"Outer membrane\",\n",
    "    \"Neuron projection\": \"Neuron projection\",\n",
    "    \"Proteasome regulatory particle, base subcomplex\": \"Proteasome base subcomplex\",\n",
    "    \"Myosin complex\": \"Myosin complex\",\n",
    "    \"Extracellular space\": \"Extracellular space\",\n",
    "    \"Anaerobic ribonucleoside-triphosphate reductase complex\": \"Anaerobic ribonucleotide reductase\",\n",
    "    \"Elongator holoenzyme complex\": \"Elongator holoenzyme complex\",\n",
    "    \"Monoatomic ion channel complex\": \"Ion channel complex\",\n",
    "    \"NatA complex\": \"NatA complex\",\n",
    "    \"Lysosome\": \"Lysosome\",\n",
    "    \"Endoplasmic reticulum\": \"Endoplasmic reticulum\",\n",
    "    \"TAT protein transport complex\": \"TAT transport complex\",\n",
    "    \"Nucleus\": \"Nucleus\",\n",
    "    \"Bicellular tight junction\": \"Tight junction\",\n",
    "    \"Phosphorelay sensor kinase activity\": \"Phosphorelay kinase\",\n",
    "    \"ABC-type transporter activity\": \"ABC transporter\",\n",
    "    \"Protein kinase activity\": \"Protein kinase\",\n",
    "    \"Hydrolase activity\": \"Hydrolase\",\n",
    "    \"ATP binding\": \"ATP binding\",\n",
    "    \"Catalytic activity\": \"Catalytic activity\",\n",
    "    \"ATP-dependent chromatin remodeler activity\": \"Chromatin remodeler (ATP-dependent)\",\n",
    "    \"Transferase activity\": \"Transferase\",\n",
    "    \"Metallopeptidase activity\": \"Metallopeptidase\",\n",
    "    \"Carboxypeptidase activity\": \"Carboxypeptidase\",\n",
    "    \"D-malate dehydrogenase (decarboxylating) (NAD+) activity\": \"D-malate dehydrogenase (NAD+)\",\n",
    "    \"Protein serine/threonine kinase activity\": \"Ser/Thr protein kinase\",\n",
    "    \"RNA polymerase II cis-regulatory region sequence-specific DNA binding\": \"Pol II cis-regulatory DNA binding\",\n",
    "    \"Oxidoreductase activity, acting on iron-sulfur proteins as donors\": \"Fe-S protein oxidoreductase\",\n",
    "    \"DNA-binding transcription factor activity, RNA polymerase II-specific\": \"Pol II-specific transcription factor\",\n",
    "    \"Zinc ion binding\": \"Zinc binding\",\n",
    "    \"Heme binding\": \"Heme binding\",\n",
    "    \"Guanyl-nucleotide exchange factor activity\": \"GEF activity\",\n",
    "    \"Ubiquitin protein ligase activity\": \"Ubiquitin ligase\",\n",
    "    \"S-(hydroxymethyl)glutathione dehydrogenase [NAD(P)+] activity\": \"S-HMG dehydrogenase\"\n",
    "    }\n",
    "\n",
    "# # Save the dictionary\n",
    "# with open(\"go_term_mapping.pkl\", \"wb\") as file:\n",
    "#     pickle.dump(go_term_mapping, file)\n",
    "    \n",
    "# with open(\"go_term_mapping.pkl\", \"rb\") as file:\n",
    "#     go_term_mapping = pickle.load(file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cfb807-9df5-4d5b-a02f-e2f1d2462724",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_enrichment_files(base_dirs: Dict[str, pathlib.PosixPath], patterns: Dict[str, str]) -> Dict[str, pl.DataFrame]:\n",
    "    \"\"\"\n",
    "    Reads all parquet files from the multi-species entry enrichment results and the multi-species GOEA results and adds Phylum information.\n",
    "    \"\"\"\n",
    "    result_dfs = {}\n",
    "    \n",
    "    # Process each data type (domains, families, go_terms)\n",
    "    for data_type, base_dir in base_dirs.items():\n",
    "        file_pattern = patterns[data_type]\n",
    "        parquet_files = list(base_dir.glob(f\"*{file_pattern}\"))\n",
    "        \n",
    "        if not parquet_files:\n",
    "            raise ValueError(f\"No parquet files found matching pattern '{file_pattern}' in {base_dir}\")\n",
    "        \n",
    "        # Read the first file to get schema\n",
    "        first_df = pl.read_parquet(parquet_files[0])\n",
    "        schema = first_df.schema\n",
    "        \n",
    "        # Initialize list to store dataframes for current data type\n",
    "        dfs = []\n",
    "        \n",
    "        # Process each file\n",
    "        for file_path in parquet_files:\n",
    "            # Extract phylum name from filename\n",
    "            phylum = (file_path.name\n",
    "                     .split(file_pattern.split(\"_\")[1])[0]\n",
    "                     .rstrip('_')\n",
    "                     .replace(\"_\", \" \"))\n",
    "            \n",
    "            # Read and process the parquet file\n",
    "            df = (pl.read_parquet(file_path)\n",
    "                 .cast(schema)\n",
    "                 .with_columns(pl.lit(phylum).alias(\"Phylum\")))\n",
    "            \n",
    "            dfs.append(df)\n",
    "        \n",
    "        # Combine all dataframes for current data type\n",
    "        result_dfs[data_type] = pl.concat(dfs)\n",
    "    \n",
    "    return result_dfs\n",
    "\n",
    "enrichment_dfs = read_enrichment_files(\n",
    "    base_dirs={\n",
    "        'domains': combined_enrichment_dirs[\"combined_domains\"],\n",
    "        'families': combined_enrichment_dirs[\"combined_families\"],\n",
    "        'go_terms': combined_enrichment_dirs[\"combined_go_terms\"]\n",
    "    },\n",
    "    patterns={\n",
    "        'domains': patterns[\"domains\"],\n",
    "        'families': patterns[\"families\"],\n",
    "        'go_terms': patterns[\"go_terms\"]\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e5808c-a0f4-4b70-9d40-99fbf005eb18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This is a nested dictionary with the exact mapping of how the data are classifiied in domains, kingdoms and phyla\n",
    "# The data are ordered as follows:\n",
    "#     Domain\n",
    "#         Kingdom\n",
    "#             Phylum\n",
    "\n",
    "domain_to_kingdom_to_phylum = {\n",
    "    'Archaea':{\n",
    "        'Archaea': [\n",
    "            'Euryarchaeota', 'Nanoarchaeota', 'Nitrososphaerota', \n",
    "            'Thermoproteota', 'Candidatus Woesearchaeota', 'Candidatus Undinarchaeota',\n",
    "            'Candidatus Thorarchaeota', 'Candidatus Thermoplasmatota', 'Candidatus Parvarchaeota',\n",
    "            'Candidatus Nanohaloarchaeota', 'Candidatus Micrarchaeota', 'Candidatus Lokiarchaeota',\n",
    "            'Candidatus Korarchaeota', 'Candidatus Diapherotrites', 'Candidatus Bathyarchaeota',\n",
    "            'Candidatus Altarchaeota', 'Candidatus Aenigmarchaeota', 'Archaeal Incertae sedis'\n",
    "        ]\n",
    "    },\n",
    "    'Bacteria':{\n",
    "        'Bacteria':[\n",
    "            'Abditibacteriota','Acidobacteriota', 'Actinomycetota', \n",
    "            'Aquificota', 'Armatimonadota','Atribacterota', \n",
    "            'Bacillota', 'Bacteroidota', 'Balneolota', \n",
    "            'Bdellovibrionota', 'Caldisericota', 'Calditrichota', \n",
    "            'Campylobacterota','Chlorobiota', 'Chloroflexota', \n",
    "            'Chlamydiota', 'Chrysiogenota', 'Coprothermobacterota', \n",
    "            'Cyanobacteriota', 'Deferribacterota', 'Deinococcota', \n",
    "            'Dictyoglomota', 'Elusimicrobiota', 'Fibrobacterota', \n",
    "            'Fusobacteriota', 'Gemmatimonadota','Ignavibacteriota', \n",
    "            'Kiritimatiellota', 'Lentisphaerota', 'Mycoplasmatota', \n",
    "            'Myxococcota', 'Nitrospinota', 'Nitrospirota', \n",
    "            'Planctomycetota','Pseudomonadota', 'Rhodothermota', \n",
    "            'Spirochaetota', 'Synergistota', 'Thermodesulfobacteriota',\n",
    "            'Thermotogota', 'Verrucomicrobiota', 'Candidatus Tectomicrobia', \n",
    "            'Thermodesulfobiota','Thermomicrobiota', 'Candidatus Saccharibacteria',\n",
    "            'Candidatus Poribacteria', 'Candidatus Parcubacteria', 'Candidatus Paceibacterota',\n",
    "            'Candidatus Omnitrophota', 'Candidatus Nomurabacteria', 'Candidatus Moduliflexota',\n",
    "            'Candidatus Melainabacteria', 'Candidatus Mcinerneyibacteriota', 'Candidatus Marinimicrobia',\n",
    "            'Candidatus Margulisiibacteriota', 'Candidatus Lithacetigenota', 'Candidatus Latescibacteria',\n",
    "            'Candidatus Kryptonia', 'Candidatus Kapabacteria', 'Candidatus Hydrogenedentes',\n",
    "            'Candidatus Gracilibacteria', 'Candidatus Dormibacteraeota', 'Candidatus Cryosericota',\n",
    "            'Candidatus Cloacimonadota', 'Candidatus Bipolaricaulota', 'Candidatus Absconditabacteria',\n",
    "            'Candidate division Zixibacteria', 'Candidate division NC10', 'Bacterial Incertae sedis'\n",
    "        ],\n",
    "    },\n",
    "    'Eukaryota':{\n",
    "        'Fungi':[\n",
    "            'Ascomycota','Basidiomycota','Blastocladiomycota', \n",
    "                 'Chytridiomycota', 'Cryptomycota', 'Mucoromycota', \n",
    "                 'Olpidiomycota','Oomycota', 'Zoopagomycota', \n",
    "                 'Microsporidia', 'Fungal Incertae sedis'\n",
    "        ],\n",
    "        'Metazoa':[\n",
    "            'Annelida', 'Arthropoda', 'Brachiopoda', \n",
    "                   'Bryozoa','Chordata', 'Cnidaria', \n",
    "                   'Echinodermata', 'Mollusca','Nematoda', \n",
    "                   'Orthonectida', 'Placozoa', 'Platyhelminthes', \n",
    "                   'Porifera', 'Rotifera', 'Tardigrada', 'Fornicata'\n",
    "        ],\n",
    "        'Protista':[\n",
    "            'Apicomplexa', 'Bacillariophyta', 'Cercozoa', \n",
    "                    'Ciliophora','Discosea', \n",
    "                    'Euglenozoa', 'Foraminifera', 'Haptophyta', \n",
    "                    'Heterolobosea', 'Parabasalia', 'Perkinsozoa', \n",
    "                    'Rhodophyta', 'Endomyxa', 'Evosea', 'Bigyra',\n",
    "                    'Choanozoa', 'Cryptophyta', 'Heliozoa', 'Loukozoa',\n",
    "                    'Metamonada', 'Myzozoa', 'Ochrophyta', 'Sulcozoa'\n",
    "        ],\n",
    "        'Viridiplantae':[\n",
    "            'Chlorophyta', 'Streptophyta'\n",
    "        ]\n",
    "    },\n",
    "    'Viruses':{\n",
    "        'Bamfordvirae':[\n",
    "            'Nucleocytoviricota','Preplasmiviricota'\n",
    "        ],\n",
    "        'Helvetiavirae':[\n",
    "            'Dividoviricota'\n",
    "        ],\n",
    "        'Heunggongvirae':[\n",
    "            'Peploviricota','Uroviricota'\n",
    "        ],\n",
    "        'Loebvirae':[\n",
    "            'Hofneiviricota'\n",
    "        ],\n",
    "        'Orthornavirae':[\n",
    "            'Duplornaviricota','Kitrinoviricota','Lenarviricota',\n",
    "                         'Negarnaviricota','Pisuviricota', 'Orthornavirae Incertae sedis'\n",
    "        ],\n",
    "        'Pararnavirae':[\n",
    "            'Artverviricota'\n",
    "        ],\n",
    "        'Sangervirae':[\n",
    "            'Phixviricota'\n",
    "        ],\n",
    "        'Shotokuvirae':[\n",
    "            'Cossaviricota','Cressdnaviricota'\n",
    "        ],\n",
    "        'Trapavirae':[\n",
    "            'Saleviricota'\n",
    "        ],\n",
    "        'Zilligvirae':[\n",
    "            'Taleaviricota'\n",
    "        ],\n",
    "        'Viral Incertae sedis':[\n",
    "            \"Viral Incertae sedis\"\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "def sort_dictionary(domain_to_kingdom_to_phylum):\n",
    "    \"\"\"\n",
    "    Sorts a nested dictionary structure containing domains, kingdoms, and phyla.\n",
    "    \"\"\"\n",
    "    sorted_dict = {}\n",
    "    \n",
    "    # Sort domains\n",
    "    for domain in sorted(domain_to_kingdom_to_phylum.keys()):\n",
    "        sorted_dict[domain] = {}\n",
    "        \n",
    "        # Sort kingdoms within each domain\n",
    "        for kingdom in sorted(domain_to_kingdom_to_phylum[domain].keys()):\n",
    "            # Sort phyla within each kingdom\n",
    "            sorted_phyla = sorted(domain_to_kingdom_to_phylum[domain][kingdom])\n",
    "            sorted_dict[domain][kingdom] = sorted_phyla\n",
    "            \n",
    "    return sorted_dict\n",
    "\n",
    "# Create the sorted dictionary\n",
    "domain_to_kingdom_to_phylum = sort_dictionary(domain_to_kingdom_to_phylum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5aca7c8-fcc3-4f44-bbc0-ee5e99442c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def fetch_short_name(session: aiohttp.ClientSession, \n",
    "                         interpro_id: str, \n",
    "                         semaphore: asyncio.Semaphore) -> Tuple[str, Optional[str]]:\n",
    "    \"\"\"\n",
    "    Fetch short name for a single InterPro ID.\n",
    "    Returns tuple of (interpro_id, short_name) to maintain order.\n",
    "    \"\"\"\n",
    "    url = f\"https://www.ebi.ac.uk/interpro/api/entry/interpro/{interpro_id}\"\n",
    "    \n",
    "    try:\n",
    "        async with semaphore:\n",
    "            async with session.get(url) as response:\n",
    "                if response.status == 200:\n",
    "                    data = await response.json()\n",
    "                    return interpro_id, data[\"metadata\"][\"name\"].get(\"short\")\n",
    "                elif response.status == 410:\n",
    "                    return interpro_id, None\n",
    "                else:\n",
    "                    return interpro_id, None\n",
    "    except aiohttp.ClientError as e:\n",
    "        print(f\"Network error for {interpro_id}: {str(e)}\")\n",
    "        return interpro_id, None\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error for {interpro_id}: {str(e)}\")\n",
    "        return interpro_id, None\n",
    "\n",
    "async def fetch_all_short_names(interpro_ids: List[str], \n",
    "                              max_concurrent: int = 10) -> Dict[str, Optional[str]]:\n",
    "    \"\"\"Fetch short names for all InterPro IDs concurrently.\"\"\"\n",
    "    semaphore = asyncio.Semaphore(max_concurrent)\n",
    "    \n",
    "    timeout = aiohttp.ClientTimeout(total=60, connect=30)\n",
    "    \n",
    "    connector = aiohttp.TCPConnector(limit=max_concurrent,\n",
    "                                   force_close=False,\n",
    "                                   enable_cleanup_closed=True)\n",
    "    \n",
    "    async with aiohttp.ClientSession(timeout=timeout,\n",
    "                                   connector=connector,\n",
    "                                   raise_for_status=False) as session:\n",
    "        tasks = []\n",
    "        for id_ in interpro_ids:\n",
    "            task = asyncio.create_task(fetch_short_name(session, id_, semaphore))\n",
    "            tasks.append(task)\n",
    "        \n",
    "        results_dict = {}\n",
    "        try:\n",
    "            # Create progress bar before starting task processing\n",
    "            pbar = tqdm(total=len(tasks), desc=\"Fetching InterPro data\")\n",
    "            \n",
    "            for coro in asyncio.as_completed(tasks):\n",
    "                try:\n",
    "                    interpro_id, short_name = await coro\n",
    "                    results_dict[interpro_id] = short_name\n",
    "                    pbar.update(1)  # Update progress bar\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing result: {str(e)}\")\n",
    "                    pbar.update(1)  # Update progress even on error\n",
    "                    continue\n",
    "            pbar.close()\n",
    "        except Exception as e:\n",
    "            print(f\"Error in processing tasks: {str(e)}\")\n",
    "        finally:\n",
    "            # Cancel any remaining tasks\n",
    "            for task in tasks:\n",
    "                if not task.done():\n",
    "                    task.cancel()\n",
    "            \n",
    "            # Wait for all tasks to complete or be cancelled\n",
    "            await asyncio.gather(*tasks, return_exceptions=True)\n",
    "            \n",
    "        return results_dict\n",
    "\n",
    "def add_short_names_async(df: pl.DataFrame, max_concurrent: int = 10) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Add short names from InterPro API to the DataFrame using async processing.\n",
    "    \"\"\"\n",
    "    interpro_ids = df['Interpro_ID'].to_list()\n",
    "    try:\n",
    "        results_dict = asyncio.run(\n",
    "            fetch_all_short_names(interpro_ids, max_concurrent=max_concurrent)\n",
    "        )\n",
    "    except RuntimeError as e:\n",
    "        if \"There is no current event loop in thread\" in str(e):\n",
    "            loop = asyncio.new_event_loop()\n",
    "            asyncio.set_event_loop(loop)\n",
    "            try:\n",
    "                results_dict = loop.run_until_complete(\n",
    "                    fetch_all_short_names(interpro_ids, max_concurrent=max_concurrent)\n",
    "                )\n",
    "            finally:\n",
    "                loop.close()\n",
    "    \n",
    "    # Create short names list in original order\n",
    "    short_names = [results_dict.get(id_, None) for id_ in interpro_ids]\n",
    "    \n",
    "    # Add results to DataFrame\n",
    "    return df.with_columns(pl.Series(name='Short_Name', values=short_names))\n",
    "\n",
    "enrichment_dfs['domains'] = add_short_names_async(enrichment_dfs['domains'], max_concurrent=20)\n",
    "enrichment_dfs['families'] = add_short_names_async(enrichment_dfs['families'], max_concurrent=20)\n",
    "\n",
    "enrichment_dfs['domains']['Entry', 'Short_Name'].unique().write_csv('domains_short_names.csv')\n",
    "enrichment_dfs['families']['Entry', 'Short_Name'].unique().write_csv('families_short_names.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcac2fb4-1d6d-49f8-979f-1270ae3c149e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_domain_info(enrichment_df: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Adds the corresponding Domain to each Phylum.\n",
    "    \"\"\"\n",
    "    # Intialize an empty dictionary to store the phylum to domain mappings \n",
    "    phylum_to_domain = {}\n",
    "\n",
    "    # Create a look-up dictionary that can categorize phyla based on the greater domain level\n",
    "    for domain, kingdoms in domain_to_kingdom_to_phylum.items():\n",
    "        for kingdom, phyla in kingdoms.items():\n",
    "            for phylum in phyla:\n",
    "                phylum_to_domain[phylum] = domain\n",
    "\n",
    "    # Single-pass categorization\n",
    "    enrichment_df = enrichment_df.with_columns(\n",
    "        pl.col('Phylum').replace(phylum_to_domain).alias('Domain')\n",
    "    )\n",
    "    return enrichment_df.sort('Domain')\n",
    "\n",
    "for data_type in enrichment_dfs:\n",
    "    enrichment_dfs[data_type] = add_domain_info(enrichment_dfs[data_type])\n",
    "    if \"Short_Name\" in enrichment_dfs[data_type].columns:\n",
    "        enrichment_dfs[data_type] = enrichment_dfs[data_type].with_columns(\n",
    "            pl.col(\"Short_Name\").str.replace_all(\"_\", \" \").alias(\"Short_Name\"))\n",
    "    if \"Short_Name\" not in enrichment_dfs[data_type].columns:\n",
    "            enrichment_dfs[data_type] = enrichment_dfs[data_type].with_columns(Short_Name = pl.lit('None'))\n",
    "            enrichment_dfs[data_type] = enrichment_dfs[data_type].rename({\"Entry\" : \"GO_Term_ID\", 'Description': \"Entry\"})       \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761df244-d657-4e8d-a541-5dc64d536129",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weighted_mean(log_odds_ratios: NDArray[np.float64], standard_errors: NDArray[np.float64]) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Calculate weighted mean using Winsorized weights based on standard errors.\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(log_odds_ratios) == 0 or len(standard_errors) == 0:\n",
    "        return np.nan, np.nan\n",
    "        \n",
    "    # Remove any entries where SE is 0 or invalid\n",
    "    valid_mask = (standard_errors > 0) & ~np.isnan(standard_errors) & ~np.isnan(log_odds_ratios)\n",
    "    if not np.any(valid_mask):\n",
    "        return np.nan, np.nan\n",
    "        \n",
    "    log_odds_ratios = log_odds_ratios[valid_mask]\n",
    "    standard_errors = standard_errors[valid_mask]\n",
    "    \n",
    "    # Compute initial weights\n",
    "    weights = 1 / (standard_errors ** 2)\n",
    "    \n",
    "    # Winsorize weights at the 95th percentile\n",
    "    weight_percentile = np.percentile(weights, 95)\n",
    "    weights = np.minimum(weights, weight_percentile)\n",
    "    \n",
    "    # Calculate weighted mean and combined SE\n",
    "    combined_lor = np.sum(weights * log_odds_ratios) / np.sum(weights)\n",
    "    combined_se = np.sqrt(1 / np.sum(weights))\n",
    "    \n",
    "    return combined_lor, combined_se\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d5d122-9751-47b8-ab7f-055ef58e97bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cluster_common_go_terms(enrichiment_df: pl.DataFrame,\n",
    "                            class_to_analyse: str) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Clusters semantically similar GO Terms using Wang's method and Scipy's hierarchial clustering. \n",
    "    \"\"\"\n",
    "    \n",
    "    # Filters the dataframe to keep entries with a Adjusted P Value less than 0.05 and based on the class to analyse\n",
    "    enrichiment_df = enrichiment_df.filter((pl.col(\"Adjusted_Meta_P_Value\") <= 0.05) & (pl.col('Class') == class_to_analyse))\n",
    "    \n",
    "    # Selects only the relevant columns for the analysis\n",
    "    enrichiment_terms = enrichiment_df.select(['GO_Term_ID', 'Entry', 'Adjusted_Meta_P_Value', 'Species_Percentage','Combined_Log_Odds_Ratio', 'Combined_SE'])\n",
    "    \n",
    "    # Check if enriched_terms is empty\n",
    "    if enrichiment_terms.is_empty():\n",
    "        raise ValueError(\"The enriched_terms DataFrame is empty.\")\n",
    "\n",
    "    # Get list of GO IDs\n",
    "    go_ids = enrichiment_terms.select('GO_Term_ID').to_series().to_list()\n",
    "\n",
    "    # Calculate Wang similarity matrix\n",
    "    wang_calc = SsWang(set(go_ids), godag)\n",
    "    n_terms = len(go_ids)\n",
    "    similarity_matrix = np.zeros((n_terms, n_terms))\n",
    "\n",
    "    for i in range(n_terms):\n",
    "        for j in range(i, n_terms):\n",
    "            sim = wang_calc.get_sim(go_ids[i], go_ids[j])\n",
    "            similarity_matrix[i, j] = sim\n",
    "            similarity_matrix[j, i] = sim\n",
    "\n",
    "    # Convert similarity to distance\n",
    "    distance_matrix = 1 - similarity_matrix\n",
    "\n",
    "    # Ensure the diagonal elements are exactly zero\n",
    "    np.fill_diagonal(distance_matrix, 0)\n",
    "\n",
    "    # Convert to condensed distance matrix\n",
    "    condensed_distance = squareform(distance_matrix)\n",
    "\n",
    "    # Perform hierarchical clustering\n",
    "    linkage_matrix = linkage(condensed_distance, method='average')\n",
    "    \n",
    "    # Set GO Class specific threshold values for the clusters\n",
    "    if class_to_analyse == 'biological_process':\n",
    "        clustering_threshold = 0.54\n",
    "    elif class_to_analyse == 'molecular_function':\n",
    "        clustering_threshold = 0.535\n",
    "    elif class_to_analyse == 'cellular_component':\n",
    "        clustering_threshold = 0.52\n",
    "    \n",
    "    # Adjust threshold calculation\n",
    "    distance_threshold = 1 - clustering_threshold\n",
    "    clusters = fcluster(linkage_matrix, t = distance_threshold, criterion='distance')\n",
    "\n",
    "    # Process clusters\n",
    "    results = []\n",
    "\n",
    "    unique_clusters, counts = np.unique(clusters, return_counts=True)\n",
    "    cluster_counts = dict(zip(unique_clusters, counts))\n",
    "\n",
    "    for cluster_id in unique_clusters:\n",
    "        # Get indices of terms in this cluster\n",
    "        cluster_indices = np.where(clusters == cluster_id)[0]\n",
    "        cluster_size = len(cluster_indices)\n",
    "\n",
    "        # Get GO IDs and terms in this cluster\n",
    "        cluster_go_ids = [go_ids[i] for i in cluster_indices]\n",
    "        cluster_terms = enrichiment_terms.filter(pl.col('GO_Term_ID').is_in(cluster_go_ids))\n",
    "\n",
    "        if cluster_size >= 2:\n",
    "            # Select representative term (most significant p-value)\n",
    "            min_p_value = cluster_terms['Adjusted_Meta_P_Value'].min()\n",
    "            representative_terms = cluster_terms.filter(pl.col('Adjusted_Meta_P_Value') == min_p_value)\n",
    "\n",
    "            # Among those terms, select the ones with highest Species_Percentage\n",
    "            max_species_percentage = representative_terms['Species_Percentage'].max()\n",
    "            representative_terms = representative_terms.filter(pl.col('Species_Percentage') == max_species_percentage)\n",
    "\n",
    "            # Handle ties by selecting the term with the highest Combined_Log_Odds_Ratio\n",
    "            max_combined_lor = representative_terms['Combined_Log_Odds_Ratio'].max()\n",
    "            representative_terms = representative_terms.filter(pl.col('Combined_Log_Odds_Ratio') == max_combined_lor)\n",
    "\n",
    "            # Finally, select the first term\n",
    "            representative_term = representative_terms.row(0)\n",
    "\n",
    "            # Improved calculation of mean similarity within cluster\n",
    "            cluster_indices_array = np.array(cluster_indices)\n",
    "            cluster_similarity_matrix = similarity_matrix[np.ix_(cluster_indices_array, cluster_indices_array)]\n",
    "            np.fill_diagonal(cluster_similarity_matrix, np.nan)\n",
    "            mean_similarity = np.nanmean(cluster_similarity_matrix)\n",
    "\n",
    "            # Extract LORs and SEs\n",
    "            lor_list = cluster_terms.select(pl.col('Combined_Log_Odds_Ratio')).to_series().to_numpy()\n",
    "            se_list = cluster_terms.select(pl.col('Combined_SE')).to_series().to_numpy()\n",
    "            species_percentage_list = cluster_terms.select(pl.col('Species_Percentage')).to_series().to_numpy()\n",
    "\n",
    "            # Ensure SEs are positive and non-zero\n",
    "            valid_indices = se_list > 0\n",
    "            lor_list = lor_list[valid_indices]\n",
    "            se_list = se_list[valid_indices]\n",
    "            species_percentage_list = species_percentage_list[valid_indices]\n",
    "\n",
    "            if len(lor_list) > 0:\n",
    "                # Recalculate combined LOR and SE using Winsorized weights\n",
    "                combined_lor, combined_se = calculate_weighted_mean(lor_list, se_list)\n",
    "            else:\n",
    "                # Handle case where all SEs are zero or invalid\n",
    "                combined_lor = np.nan\n",
    "                combined_se = np.nan\n",
    "\n",
    "            # Calculate combined Species_Percentage as simple mean\n",
    "            if len(species_percentage_list) > 0:\n",
    "                combined_species_percentage = np.mean(species_percentage_list)\n",
    "            else:\n",
    "                combined_species_percentage = np.nan\n",
    "\n",
    "            results.append({\n",
    "                'GO_Term_ID': representative_term[0],\n",
    "                'Representative_Description': representative_term[1], \n",
    "                'Cluster_Size': cluster_size,\n",
    "                'Mean_Similarity': mean_similarity,\n",
    "                'Representative_LOR': combined_lor,\n",
    "                'Representative_SE': combined_se,\n",
    "                'Representative_Percentage': combined_species_percentage,\n",
    "                'Member_GOs': ', '.join(cluster_go_ids)\n",
    "            })\n",
    "        elif cluster_size == 1:\n",
    "            # Handle singleton clusters\n",
    "            term_idx = cluster_indices[0]\n",
    "            term = enrichiment_terms.filter(pl.col('GO_Term_ID') == go_ids[term_idx]).row(0)\n",
    "            if term[2] < 0.05:  \n",
    "                results.append({\n",
    "                    'GO_Term_ID': term[0],\n",
    "                    'Representative_Description': term[1],  \n",
    "                    'Cluster_Size': 1,\n",
    "                    'Mean_Similarity': 1.0,\n",
    "                    'Representative_LOR': term[4],  \n",
    "                    'Representative_SE': term[5],  \n",
    "                    'Representative_Percentage': term[3], \n",
    "                    'Member_GOs': term[0]\n",
    "                })\n",
    "\n",
    "    \n",
    "    result_df = pl.DataFrame(results)\n",
    "    \n",
    "    # Create a final dataframe that combines the clusters to the original dataframe\n",
    "    final_df = (enrichiment_df\n",
    "           .filter(pl.col(\"GO_Term_ID\").is_in(result_df['GO_Term_ID']))\n",
    "           .drop(\"Entry\", \n",
    "                 \"Species_Percentage\",\n",
    "                 'Combined_Log_Odds_Ratio', \n",
    "                 'Combined_SE')\n",
    "           .join(result_df, on='GO_Term_ID'))\n",
    "           \n",
    "    return final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7564c1b-b963-4d0d-8366-ea71a77b2e1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define classes of GO terms to be used for later analyses\n",
    "classes = ['biological_process', 'molecular_function', 'cellular_component']\n",
    "\n",
    "def process_phylum_go_terms(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Process GO terms clustering for each phylum and class combination, then combine results.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get unique phyla and classes\n",
    "    phyla = df.select('Phylum').unique().to_series().to_list()\n",
    "    \n",
    "    # Store results for each phylum\n",
    "    phylum_results = []\n",
    "    \n",
    "    for phylum in phyla:        \n",
    "        # Filter data for current phylum\n",
    "        phylum_df = df.filter(pl.col('Phylum') == phylum)\n",
    "        \n",
    "        # Store results for each class within the phylum\n",
    "        class_results = []\n",
    "        \n",
    "        for class_name in classes:\n",
    "            try:\n",
    "                # Process the class-specific clustering\n",
    "                class_result = cluster_common_go_terms(\n",
    "                    enrichiment_df=phylum_df,\n",
    "                    class_to_analyse=class_name\n",
    "                )\n",
    "                \n",
    "                if not class_result.is_empty():\n",
    "                    # Add phylum and class information if not already present\n",
    "                    class_result = class_result.with_columns([\n",
    "                        pl.lit(phylum).alias('Phylum'),\n",
    "                        pl.lit(class_name).alias('Class')\n",
    "                    ])\n",
    "                    \n",
    "                    class_results.append(class_result)\n",
    "                    \n",
    "                    \n",
    "            except ValueError as e:\n",
    "                continue\n",
    "        \n",
    "        if class_results:\n",
    "            phylum_result = pl.concat(class_results, how='vertical')\n",
    "            phylum_results.append(phylum_result)\n",
    "    \n",
    "    # Combine results from all phyla\n",
    "    if not phylum_results:\n",
    "        raise ValueError(\"No results were generated for any phylum\")\n",
    "    \n",
    "    final_results = pl.concat(phylum_results, how='vertical')\n",
    "    \n",
    "    # Sort the results by Phylum, Class, and cluster size\n",
    "    final_results = final_results.sort(\n",
    "        ['Phylum', 'Class', 'Cluster_Size', 'Representative_LOR'], \n",
    "        descending=[False, False, True, True]\n",
    "    )\n",
    "    \n",
    "    return final_results\n",
    "\n",
    "def process_go_enrichment(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Wrapper function to process GO enrichment data with error handling.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        results = process_phylum_go_terms(df)\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing GO enrichment: {str(e)}\")\n",
    "        return pl.DataFrame()\n",
    "\n",
    "clustered_go_terms = process_go_enrichment(enrichment_dfs['go_terms'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce5acd4-e024-419c-b005-dffb9735aa3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_phylum_coverage(\n",
    "    entry_enrichment_df: pl.DataFrame,\n",
    "    id_type: Literal['go', 'interpro'] = 'interpro',\n",
    "    default_class: str = 'biological_process') -> Tuple[pl.DataFrame, pl.DataFrame]:\n",
    "    \"\"\"\n",
    "    Calculate phylum coverage for either GO terms or InterPro IDs.\n",
    "    \"\"\"\n",
    "    # Define ID column name based on type\n",
    "    id_col = 'GO_Term_ID' if id_type == 'go' else 'Interpro_ID'\n",
    "    \n",
    "    # Define schema based on ID type\n",
    "    base_schema = {\n",
    "        'Entry': pl.Utf8,\n",
    "        'Interpro_ID': pl.Utf8,\n",
    "        'Species_Count': pl.Int64,\n",
    "        'Species_Percentage': pl.Float64,\n",
    "        'Combined_Log_Odds_Ratio': pl.Float64,\n",
    "        'Combined_SE': pl.Float64,\n",
    "        'P_Value': pl.Float64,\n",
    "        'Adjusted_Meta_P_Value': pl.Float64,\n",
    "        'Log_Odds_Ratio_List': pl.List(pl.Float64),\n",
    "        'SE_Log_Odds_Ratio_List': pl.List(pl.Float64),\n",
    "        'Phylum': pl.Utf8,\n",
    "        'Short_Name': pl.Utf8,\n",
    "        'Domain': pl.Utf8,\n",
    "        'Entry_Domain_of_Origin': pl.Utf8,\n",
    "        'Phyla_with_entry': pl.Int64,\n",
    "        'Total_number_of_Phyla': pl.Int64,\n",
    "        'Phylum_coverage': pl.Float64,\n",
    "        'Counter': pl.Int64\n",
    "    }\n",
    "    \n",
    "    # Add GO-specific fields if needed\n",
    "    schema = base_schema.copy()\n",
    "    if id_type == 'go':\n",
    "        schema.update({\n",
    "            'GO_Term_ID': pl.Utf8,\n",
    "            'Class': pl.Utf8\n",
    "        })\n",
    "    \n",
    "    # Filter to keep only statistically significant entries\n",
    "    entry_enrichment_df = entry_enrichment_df.filter(pl.col(\"Adjusted_Meta_P_Value\") < 0.05)\n",
    "\n",
    "    # Calculate the total number of Phyla per Domain\n",
    "    domain_phylum_counts = entry_enrichment_df.group_by('Domain').agg(\n",
    "        n_phyla=pl.col('Phylum').n_unique()\n",
    "    )\n",
    "\n",
    "    entry_domain_phylum_counts = (\n",
    "        entry_enrichment_df\n",
    "        .filter(pl.col('Combined_Log_Odds_Ratio').is_not_null())\n",
    "        .group_by(['Domain', id_col])\n",
    "        .agg(\n",
    "            n_phyla_entry=pl.col('Phylum').n_unique(),\n",
    "            lor_list=pl.col('Combined_Log_Odds_Ratio'),\n",
    "            se_list=pl.col('Combined_SE'),\n",
    "            first_entry=pl.col('Entry').first(),\n",
    "            first_short_name=pl.col('Short_Name').first()\n",
    "        )\n",
    "        .with_columns([\n",
    "            pl.struct(['lor_list', 'se_list'])\n",
    "            .map_elements(lambda x: calculate_weighted_mean(\n",
    "                np.array(x['lor_list']), \n",
    "                np.array(x['se_list'])\n",
    "            ), return_dtype=pl.List(pl.Float64))\n",
    "            .alias('weighted_stats')\n",
    "        ])\n",
    "        .with_columns([\n",
    "            pl.col('weighted_stats').list.get(0).alias('mean_combined_log_odds_ratio'),\n",
    "            pl.col('weighted_stats').list.get(1).alias('combined_se')\n",
    "        ])\n",
    "        .drop(['lor_list', 'se_list', 'weighted_stats'])\n",
    "    )\n",
    "\n",
    "    entry_domain_phylum_counts = entry_domain_phylum_counts.sort(['Domain', \"n_phyla_entry\"], descending=[False, True])\n",
    "\n",
    "    # Merge the counts to compute the percentage of Phyla each Entry covers in its Domain\n",
    "    entry_phylum_coverage = entry_domain_phylum_counts.join(domain_phylum_counts, on='Domain')\n",
    "    entry_phylum_coverage = entry_phylum_coverage.with_columns(\n",
    "        phylum_coverage_percentage=(pl.col('n_phyla_entry') / pl.col('n_phyla') * 100)\n",
    "    )\n",
    "\n",
    "    # Rename columns\n",
    "    entry_phylum_coverage = entry_phylum_coverage.rename({\n",
    "        'n_phyla': \"Total_number_of_Phyla\",\n",
    "        'n_phyla_entry': \"Phyla_with_entry\",\n",
    "        'phylum_coverage_percentage': \"Phylum_coverage\",\n",
    "        'mean_combined_log_odds_ratio': \"Mean_Log_Odds_Ratio\"\n",
    "    })\n",
    "\n",
    "    selected_ids = set()\n",
    "    selected_rows = []\n",
    "\n",
    "    for domain in sorted(list(entry_enrichment_df['Domain'].unique())):\n",
    "        domain_entries = (entry_phylum_coverage\n",
    "            .filter(pl.col(\"Domain\") == domain)\n",
    "            .sort([\"Phylum_coverage\", 'Mean_Log_Odds_Ratio'], descending=[True, True])\n",
    "        )\n",
    "\n",
    "        domain_entries_selected = 0\n",
    "\n",
    "        for row in domain_entries.iter_rows(named=True):\n",
    "            if domain_entries_selected >= 10:\n",
    "                break\n",
    "\n",
    "            if row[id_col] not in selected_ids:\n",
    "                selected_ids.add(row[id_col])\n",
    "                selected_rows.append(row)\n",
    "                domain_entries_selected += 1\n",
    "\n",
    "    # Create DataFrame with selected entries\n",
    "    entries_to_keep_df = pl.DataFrame(selected_rows).sort([\"Domain\", \"Phylum_coverage\"], descending=[False, True])\n",
    "    entries_to_keep_df = entries_to_keep_df.with_columns(pl.arange(1, entries_to_keep_df.height + 1).alias(\"Counter\"))\n",
    "\n",
    "    entries_to_keep = entries_to_keep_df.select([id_col, 'Counter'])\n",
    "    entries_to_keep = dict(entries_to_keep.iter_rows())\n",
    "\n",
    "    # Join the coverage information back to the original DataFrame\n",
    "    # Modified to keep all necessary columns\n",
    "    result_df = entry_enrichment_df.join(\n",
    "        entry_phylum_coverage.select(pl.exclude(['first_entry'])), \n",
    "        on=['Domain', id_col]\n",
    "    )\n",
    "\n",
    "    # Filter the top entries and add a column for the original domain\n",
    "    filtered_results_df = result_df.filter(pl.col(id_col).is_in(entries_to_keep.keys())).join(\n",
    "        entries_to_keep_df.select([id_col, 'Domain', 'Counter', 'first_short_name']).rename({'Domain': 'Entry_Domain_of_Origin'}),\n",
    "        on=id_col\n",
    "    )\n",
    "    filtered_results_df = filtered_results_df.drop(\"Mean_Log_Odds_Ratio\")\n",
    "\n",
    "    # Initialize new_df with filtered_results_df\n",
    "    new_df = filtered_results_df.cast(schema)\n",
    "    new_df = new_df.select(list(schema.keys()))\n",
    "\n",
    "    # Create a list to store new rows\n",
    "    new_rows = []\n",
    "\n",
    "    # Get unique phyla from the dataframe\n",
    "    unique_phyla = filtered_results_df['Phylum'].unique()\n",
    "\n",
    "    # For each phylum\n",
    "    for phylum in unique_phyla:\n",
    "        # Get existing entries for this phylum\n",
    "        phylum_ids = filtered_results_df.filter(pl.col(\"Phylum\") == phylum)[id_col].to_list()\n",
    "\n",
    "        # Find missing entries\n",
    "        missing_ids = set(list(entries_to_keep.keys())) - set(phylum_ids)\n",
    "\n",
    "        if missing_ids:\n",
    "            # For each missing entry\n",
    "            for entry_id in missing_ids:\n",
    "                # Get the entry's original information using named columns\n",
    "                entry_info = entries_to_keep_df.filter(pl.col(id_col) == entry_id).row(0, named=True)\n",
    "                entry_coverage = entry_phylum_coverage.filter(pl.col(id_col) == entry_id).row(0, named=True)\n",
    "\n",
    "                # Create base new row with named column access\n",
    "                new_row = {\n",
    "                    'Entry': entry_coverage['first_entry'],\n",
    "                    'Interpro_ID': 'IPR000000' if id_type == 'go' else entry_id,\n",
    "                    'Species_Count': 0,\n",
    "                    'Species_Percentage': 0.0,\n",
    "                    'Combined_Log_Odds_Ratio': 0.0,\n",
    "                    'Combined_SE': 0.0,\n",
    "                    'P_Value': 1.0,\n",
    "                    'Adjusted_Meta_P_Value': 1.0,\n",
    "                    'Log_Odds_Ratio_List': [0.0],\n",
    "                    'SE_Log_Odds_Ratio_List': [0.0],\n",
    "                    'Phylum': phylum,\n",
    "                    'Short_Name': entry_coverage['first_short_name'], \n",
    "                    'Domain': entry_coverage['Domain'],\n",
    "                    'Entry_Domain_of_Origin': entry_info['Domain'],\n",
    "                    'Phyla_with_entry': entry_coverage['Phyla_with_entry'],\n",
    "                    'Total_number_of_Phyla': entry_coverage['Total_number_of_Phyla'],\n",
    "                    'Phylum_coverage': entry_coverage['Phylum_coverage'],\n",
    "                    'Counter': entries_to_keep[entry_id]\n",
    "                }\n",
    "\n",
    "                # Add GO-specific fields if needed\n",
    "                if id_type == 'go':\n",
    "                    new_row.update({\n",
    "                        'GO_Term_ID': entry_id,\n",
    "                        'Class': default_class\n",
    "                    })\n",
    "\n",
    "                new_rows.append(new_row)\n",
    "\n",
    "    # If there are new rows, concatenate them with new_df\n",
    "    if new_rows:\n",
    "        new_df = pl.concat([new_df, pl.DataFrame(new_rows, schema=schema)])\n",
    "\n",
    "    phylum_order = {}\n",
    "    order_index = 0\n",
    "\n",
    "    for domain in domain_to_kingdom_to_phylum:\n",
    "        for kingdom in domain_to_kingdom_to_phylum[domain]:\n",
    "            for phylum in domain_to_kingdom_to_phylum[domain][kingdom]:\n",
    "                phylum_order[phylum] = order_index\n",
    "                order_index += 1\n",
    "\n",
    "    # Create a temporary column for phylum ordering using a map expression\n",
    "    organized_df = (\n",
    "        new_df.with_columns([\n",
    "                (pl.col(\"Phylum\")\n",
    "                .map_elements(lambda x: phylum_order.get(x, float('inf')), return_dtype=pl.Int64)\n",
    "                .alias(\"phylum_order\")),\n",
    "                (pl.col('Combined_Log_Odds_Ratio').exp().alias('Combined_Odds_Ratio'))\n",
    "            ])\n",
    "            .sort([\"phylum_order\", \"Counter\"])\n",
    "            .drop(\"phylum_order\")\n",
    "    )\n",
    "    \n",
    "    return result_df, organized_df\n",
    "\n",
    "def process_all_dataframes(data_dict: Dict[str, pl.DataFrame]) -> Tuple[Dict[str, pl.DataFrame]]:\n",
    "    \"\"\"\n",
    "    Process all dataframes in the dictionary and handle GO terms separately by class.\n",
    "    \"\"\"\n",
    "    \n",
    "    results = {}\n",
    "    filtered_results = {}\n",
    "    \n",
    "    # Process domains and families dataframes\n",
    "    results['domains'], filtered_results['domains'] = calculate_phylum_coverage(data_dict['domains'], id_type='interpro')\n",
    "    results['families'], filtered_results['families'] = calculate_phylum_coverage(data_dict['families'], id_type='interpro')\n",
    "    \n",
    "    # Split and process GO terms by class\n",
    "    go_terms_df = data_dict['go_terms']\n",
    "    go_terms_df = go_terms_df.with_columns(Short_Name = pl.lit('None'))\n",
    "    \n",
    "    # Process biological processes\n",
    "    bio_process_df = go_terms_df.filter(pl.col('Class') == 'biological_process')\n",
    "    bio_process_df, filtered_bio_process_df = calculate_phylum_coverage(bio_process_df, id_type='go', default_class='biological_process')\n",
    "    \n",
    "    # Process molecular functions\n",
    "    mol_function_df = go_terms_df.filter(pl.col('Class') == 'molecular_function')\n",
    "    mol_function_df, filtered_mol_function_df = calculate_phylum_coverage(mol_function_df, id_type='go', default_class='molecular_function')\n",
    "    \n",
    "    # Process cellular components\n",
    "    cell_component_df = go_terms_df.filter(pl.col('Class') == 'cellular_component')\n",
    "    cell_component_df, filtered_cell_component_df = calculate_phylum_coverage(cell_component_df, id_type='go', default_class='cellular_component')\n",
    "    \n",
    "    # Concatanate into a final DataFrame and store in the dictionary\n",
    "    results['go_terms'] = pl.concat([bio_process_df, mol_function_df, cell_component_df])\n",
    "    filtered_results['go_terms'] = pl.concat([filtered_bio_process_df, filtered_mol_function_df, filtered_cell_component_df])\n",
    "\n",
    "    return results, filtered_results\n",
    "\n",
    "enrichment_dfs_with_phylum_coverage, filtered_enrichment_dfs = process_all_dataframes(enrichment_dfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5ca41f-f447-4836-937e-8bbf3e5d78b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_font_sizes(fig_width: float, \n",
    "                         fig_height: float) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Helper function to dynamically calculate font sizes for plot elements based on figure dimensions.\n",
    "    \"\"\"\n",
    "    min_dimension = min(fig_width, fig_height)\n",
    "    base_size = min_dimension * 2\n",
    "    return {\n",
    "        'axis_label': max(base_size * 1.35, 10),\n",
    "        'tick_label': max(base_size * 1.05, 8),\n",
    "        'legend': max(base_size * 1.2, 8),\n",
    "        'metric_value': max(base_size * 1, 8),\n",
    "        'table': max(base_size * 0.9, 8)\n",
    "    }\n",
    "\n",
    "def create_colorbar_legend(enrichment_df: pl.DataFrame, norm: Normalize, cmap: ListedColormap, colorbar_file: str) -> None:\n",
    "    \"\"\"\n",
    "    Creates a horizontal colorbar legend matching the main plot's color scale, with consistent dimensions to match R output.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(3, 1))\n",
    "    plt.subplots_adjust(left=0.16, right=0.84, bottom=0.3, top=0.7)\n",
    "    \n",
    "    # Use the passed colormap\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    sm.set_array([])\n",
    "    \n",
    "    cbar = plt.colorbar(sm, cax=ax, orientation='horizontal')\n",
    "    cbar.outline.set_visible(False)\n",
    "    \n",
    "    min_val = enrichment_df['Combined_Log_Odds_Ratio'].min()\n",
    "    max_val = enrichment_df['Combined_Log_Odds_Ratio'].max()\n",
    "    \n",
    "    cbar.ax.xaxis.set_label_position('top')\n",
    "    cbar.ax.set_title('ln(Enrichment)', fontsize=12, pad=10, fontweight='bold')\n",
    "    \n",
    "    tick_locations = np.linspace(min_val, max_val, num=5)\n",
    "    cbar.set_ticks(tick_locations)\n",
    "    cbar.set_ticklabels([f'{val:.1f}' for val in tick_locations])\n",
    "    cbar.ax.tick_params(labelsize=10)\n",
    "    \n",
    "    plt.savefig(colorbar_file, bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "def create_size_legend(min_size: float, max_size: float, size_legend_file: str) -> None:\n",
    "    \"\"\"\n",
    "    Creates a horizontal legend plot for the species percentage matching the main plot's size scale.\n",
    "    \"\"\"\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(3, 1))\n",
    "    \n",
    "    # Use the actual percentage values that correspond to the plot's size range\n",
    "    sizes = [0, 25, 50, 75, 100]  # Percentage values\n",
    "    x_positions = np.linspace(0.2, 0.8, len(sizes))  # Spread points horizontally\n",
    "    y_positions = np.zeros(len(sizes))  # All points at same y-level\n",
    "    \n",
    "    # Use the same size scaling as the main plot\n",
    "    scatter_sizes = np.interp(sizes, [0, 100], [min_size, max_size])\n",
    "    scatter = ax.scatter(x_positions, y_positions, \n",
    "                        s=scatter_sizes, \n",
    "                        c='black')\n",
    "    \n",
    "    # Add percentage labels below points\n",
    "    for size, x in zip(sizes, x_positions):\n",
    "        ax.text(x, -0.2, f'{size}', \n",
    "                horizontalalignment='center',\n",
    "                verticalalignment='top',\n",
    "                fontsize=10)\n",
    "    \n",
    "    # Add title above\n",
    "    ax.text(0.5, 0.5, 'Species Percentage (%)', \n",
    "            fontsize=12, \n",
    "            fontweight='bold',\n",
    "            horizontalalignment='center',\n",
    "            verticalalignment='bottom')\n",
    "    \n",
    "    # Set appropriate limits for horizontal layout\n",
    "    ax.set_xlim(-0.1, 1.1)\n",
    "    ax.set_ylim(-0.3, 0.6)\n",
    "    ax.set_axis_off()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(size_legend_file, bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55516e62-1d4f-48cd-8ba4-fd0f3af38649",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_clustered_dot_plot(\n",
    "    enrichment_df: pl.DataFrame, \n",
    "    entry_column: str, \n",
    "    plot_file_path: str, \n",
    "    cmap: ListedColormap, \n",
    "    colorbar_file: str, \n",
    "    size_legend_file: str, \n",
    "    size_legend: bool) -> None:\n",
    "    \n",
    "    \"\"\"\n",
    "    Creates a size- and color-encoded heatmap\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create main figure with simpler layout\n",
    "    fig = plt.figure(figsize=(16, 10), dpi=300) \n",
    "    gs = fig.add_gridspec(2, 20, height_ratios=[0.3, 10], hspace=0.05) \n",
    "\n",
    "    # Create domain color bar axes and main scatter plot axes\n",
    "    ax_domains = fig.add_subplot(gs[0, :19])\n",
    "    ax = fig.add_subplot(gs[1, :19])\n",
    "    \n",
    "    # Define size range \n",
    "    min_size = 10  \n",
    "    max_size = 100  \n",
    "\n",
    "    # Create linear normalization since values are already log-transformed\n",
    "    norm = Normalize(vmin=enrichment_df['Combined_Log_Odds_Ratio'].min(), \n",
    "                    vmax=enrichment_df['Combined_Log_Odds_Ratio'].max())\n",
    "\n",
    "    sns.scatterplot(data=enrichment_df.to_pandas(), \n",
    "                    x='Phylum',\n",
    "                    y=entry_column,\n",
    "                    size='Species_Percentage',\n",
    "                    hue='Combined_Log_Odds_Ratio',\n",
    "                    sizes=(min_size, max_size),\n",
    "                    palette=cmap,\n",
    "                    hue_norm=norm,\n",
    "                    ax=ax,\n",
    "                    legend=False)\n",
    "\n",
    "    # Update x-axis tick labels\n",
    "    x_ticks = range(len(ax.get_xticklabels()))\n",
    "    x_labels = [label.get_text() for label in ax.get_xticklabels()]\n",
    "    \n",
    "    # Update y-axis tick labels\n",
    "    y_ticks = range(len(ax.get_yticklabels()))\n",
    "    y_labels = [label.get_text() for label in ax.get_yticklabels()]\n",
    "    y_labels = [go_term_mapping.get(label, label) for label in y_labels]\n",
    "    \n",
    "    # Set the tick positions and new labels with adjusted font sizes\n",
    "    ax.yaxis.set_major_locator(FixedLocator(y_ticks))\n",
    "    ax.set_yticklabels(y_labels, fontsize=13, va='center') \n",
    "\n",
    "    ax.set_xlim(left=-1, right=(enrichment_df['Phylum'].n_unique()))\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('')\n",
    "\n",
    "    # Hide domain axes ticks\n",
    "    ax_domains.axis('off')\n",
    "\n",
    "    # Get phyla in plot order and create position mapping\n",
    "    phyla_in_plot = x_labels\n",
    "    x_positions = {phylum: i for i, phylum in enumerate(phyla_in_plot)}\n",
    "\n",
    "    # Create phylum to lineage mapping\n",
    "    phylum_to_lineage = {}\n",
    "    for domain in domain_to_kingdom_to_phylum:\n",
    "        for kingdom in domain_to_kingdom_to_phylum[domain]:\n",
    "            phyla = domain_to_kingdom_to_phylum[domain][kingdom]\n",
    "            for phylum in phyla:\n",
    "                phylum_to_lineage[phylum] = (domain, kingdom)\n",
    "\n",
    "    # Define domain colors\n",
    "    domain_colors = {\n",
    "        'Archaea': '#0072b2',\n",
    "        'Bacteria': '#e69f00',\n",
    "        'Eukaryota': '#009e73',\n",
    "        'Viruses': '#cc79a7'\n",
    "    }\n",
    "\n",
    "    # Create domain to x positions mapping\n",
    "    domain_to_x_positions = {}\n",
    "    for domain in domain_colors.keys():\n",
    "        phyla_in_domain = [phylum for phylum in phyla_in_plot \n",
    "                          if phylum_to_lineage.get(phylum, (None, None))[0] == domain]\n",
    "        x_positions_in_domain = [x_positions[phylum] for phylum in phyla_in_domain]\n",
    "        domain_to_x_positions[domain] = x_positions_in_domain\n",
    "\n",
    "    # Add colored rectangles for domains with adjusted text size\n",
    "    for domain in domain_colors.keys():\n",
    "        x_positions_in_domain = domain_to_x_positions.get(domain, [])\n",
    "        if x_positions_in_domain:\n",
    "            min_x_domain = min(x_positions_in_domain) - 0.5\n",
    "            max_x_domain = max(x_positions_in_domain) + 0.5\n",
    "            rect = plt.Rectangle((min_x_domain, 0), max_x_domain - min_x_domain, 1,\n",
    "                               color=domain_colors[domain], alpha=0.8)\n",
    "            ax_domains.add_patch(rect)\n",
    "\n",
    "    # Set domain axes limits\n",
    "    ax_domains.set_xlim(ax.get_xlim())\n",
    "    ax_domains.set_ylim(0, 1)\n",
    "\n",
    "    # Format x-axis labels\n",
    "    x_labels = [label.replace(\"Candidatus \", \"C. \").replace(\"Candidate \", \"C. \") for label in x_labels]\n",
    "    ax.xaxis.set_major_locator(FixedLocator(x_ticks))\n",
    "    ax.set_xticklabels(x_labels, rotation=90, ha='center', fontsize=10)\n",
    "    plt.subplots_adjust(left=0.3)  \n",
    "    \n",
    "    sns.despine()\n",
    "    plt.tight_layout(pad=0.2) \n",
    "    plt.savefig(plot_file_path, bbox_inches='tight', pad_inches=0.1, dpi=300)  \n",
    "    plt.show()\n",
    "    \n",
    "    # Create separate legends using the same normalization and size range\n",
    "    create_colorbar_legend(enrichment_df, norm, cmap, colorbar_file)\n",
    "    if size_legend:\n",
    "        create_size_legend(min_size, max_size, size_legend_file)\n",
    "    else:\n",
    "        pass \n",
    "\n",
    "create_clustered_dot_plot(\n",
    "    filtered_enrichment_dfs['domains'], \n",
    "    \"Short_Name\",\n",
    "    plots / \"domains_dotplot.svg\", \n",
    "    colormaps['domains'], \n",
    "    plots / \"domains_colorbar.svg\",  \n",
    "    plots / \"domains_size_legend.svg\",\n",
    "    size_legend = True)\n",
    "\n",
    "create_clustered_dot_plot(\n",
    "    filtered_enrichment_dfs['families'], \n",
    "    \"Short_Name\",\n",
    "    plots / \"families_dotplot.svg\", \n",
    "    colormaps['families'], \n",
    "    plots / \"families_colorbar.svg\",  \n",
    "    plots / \"families_size_legend.svg\",\n",
    "    size_legend = False)\n",
    "\n",
    "create_clustered_dot_plot(\n",
    "    filtered_enrichment_dfs['go_terms'].filter(pl.col('Class') == 'biological_process'), \n",
    "    \"Entry\",\n",
    "    plots / \"biological_process.svg\", \n",
    "    colormaps['biological_process'], \n",
    "    plots / \"biological_process_colorbar.svg\", \n",
    "    plots / \"biological_process_size_legend.svg\",\n",
    "    size_legend = False)\n",
    "\n",
    "create_clustered_dot_plot(\n",
    "    filtered_enrichment_dfs['go_terms'].filter(pl.col('Class') == 'molecular_function'), \n",
    "    \"Entry\",\n",
    "    plots / \"molecular_function.svg\", \n",
    "    colormaps['molecular_function'], \n",
    "    plots / \"molecular_function_colorbar.svg\", \n",
    "    plots / \"molecular_function_size_legend.svg\",\n",
    "    size_legend = False)\n",
    "\n",
    "create_clustered_dot_plot(\n",
    "    filtered_enrichment_dfs['go_terms'].filter(pl.col('Class') == 'cellular_component'), \n",
    "    \"Entry\",\n",
    "    plots / \"cellular_component.svg\", \n",
    "    colormaps['cellular_component'], \n",
    "    plots / \"cellular_component_colorbar.svg\", \n",
    "    plots / \"cellular_component_size_legend.svg\",\n",
    "    size_legend = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f621e31-d9d6-4a58-8dc1-9765a9405d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of representative phyla that are present in the clustered go terms to keep\n",
    "representative_phyla = [\n",
    "    \"Candidatus Lokiarchaeota\", \"Candidatus Thorarchaeota\", \"Candidatus Bathyarchaeota\",\n",
    "    \"Candidatus Woesearchaeota\", \"Candidatus Korarchaeota\", \"Chlorobiota\",\n",
    "    \"Candidate division NC10\", \"Nitrospinota\", \"Candidatus Gracilibacteria\",\n",
    "    \"Candidatus Poribacteria\", \"Cryptomycota\",\"Blastocladiomycota\",\n",
    "    \"Chordata\", \"Nematoda\", \"Mollusca\",\n",
    "    \"Tardigrada\", \"Platyhelminthes\", \"Euglenozoa\",\n",
    "    \"Ciliophora\", \"Bacillariophyta\", \"Myzozoa\",\n",
    "    \"Foraminifera\", \"Streptophyta\",\"Chlorophyta\"\n",
    "]\n",
    "\n",
    "def extract_top_phylum_entries(enrichment_df: pl.DataFrame, percentage_threshold: float, go_analysis: bool, go_class: str = None) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Extracts top 3 entries per Phylum based on either representative or combined log odds ratio.\n",
    "    \"\"\"\n",
    "    if go_analysis:\n",
    "        enrichment_df = (enrichment_df\n",
    "                        .filter((pl.col(\"Class\") == go_class) & (pl.col(\"Phylum\").is_in(representative_phyla)))\n",
    "                        .filter((pl.col(\"Representative_Percentage\") >= percentage_threshold) & \n",
    "                               (pl.col(\"Adjusted_Meta_P_Value\") <= 0.05))\n",
    "                        .sort([\"Cluster_Size\", \"Representative_LOR\", \"Phylum\"], descending=[True, True, False])\n",
    "                        .group_by(\"Phylum\")\n",
    "                        .head(3)\n",
    "                        .drop(['Log_Odds_Ratio_List', 'SE_Log_Odds_Ratio_List', 'Species_Count', \n",
    "                              'P_Value', 'GO_Term_ID', 'Member_GOs']))\n",
    "    else:\n",
    "        enrichment_df = (enrichment_df\n",
    "                        .filter(pl.col(\"Species_Percentage\") >= percentage_threshold)\n",
    "                        .filter(pl.col(\"Adjusted_Meta_P_Value\") <= 0.05)\n",
    "                        .sort([\"Combined_Log_Odds_Ratio\", \"Phylum\"], descending=[True, False])\n",
    "                        .group_by(\"Phylum\")\n",
    "                        .head(3)\n",
    "                        .drop(['Log_Odds_Ratio_List', 'SE_Log_Odds_Ratio_List', 'Species_Count', 'P_Value']))\n",
    "\n",
    "    df_columns = enrichment_df.columns\n",
    "    phylum_info = (enrichment_df.group_by(['Phylum', 'Domain'])\n",
    "                   .agg(pl.len().alias('len'))\n",
    "                   .sort('Phylum'))\n",
    "\n",
    "    new_rows = []\n",
    "    for row in phylum_info.iter_rows(named=True):\n",
    "        if row['len'] < 3:\n",
    "            base_row = {col: None for col in df_columns}\n",
    "            base_row.update({\n",
    "                'Phylum': row['Phylum'],\n",
    "                'Domain': row['Domain'],\n",
    "                'Adjusted_Meta_P_Value': 1.0,\n",
    "            })\n",
    "            \n",
    "            if go_analysis:\n",
    "                base_row.update({\n",
    "                    'Representative_Description': \" \",\n",
    "                    'Representative_LOR': 0.0,\n",
    "                    'Representative_SE': 0.0,\n",
    "                    'Representative_Percentage': 0.0,\n",
    "                    'Mean_Similarity': 0.0,\n",
    "                    'Cluster_Size': 0,\n",
    "                    'Interpro_ID': \"IPR000000\",\n",
    "                    'Short_Name': \" \",\n",
    "                    'Class': go_class\n",
    "                })\n",
    "            else:\n",
    "                base_row.update({\n",
    "                    'Entry': \" \",\n",
    "                    'Combined_Log_Odds_Ratio': 0.0,\n",
    "                    'Combined_SE': 0.0,\n",
    "                    'Species_Percentage': 0.0,\n",
    "                    'Interpro_ID': \"IPR000000\",\n",
    "                    'Short_Name': \" \"\n",
    "                })\n",
    "            \n",
    "            new_rows.extend([base_row.copy() for _ in range(3 - row['len'])])\n",
    "\n",
    "    if new_rows:\n",
    "        enrichment_df = pl.concat([enrichment_df, pl.DataFrame(new_rows)])\n",
    "\n",
    "    lor_col = \"Representative_LOR\" if go_analysis else \"Combined_Log_Odds_Ratio\"\n",
    "    se_col = \"Representative_SE\" if go_analysis else \"Combined_SE\"\n",
    "    \n",
    "    enrichment_df = enrichment_df.with_columns([\n",
    "        (1.96 * pl.col(se_col)).alias(\"MOE\"),\n",
    "        (pl.col(lor_col) - (1.96 * pl.col(se_col))).alias(\"Lower_CI\"),\n",
    "        (pl.col(lor_col) + (1.96 * pl.col(se_col))).alias(\"Upper_CI\")\n",
    "    ])\n",
    "\n",
    "    return enrichment_df.sort('Phylum')\n",
    "\n",
    "def process_and_save(df, filename, go_analysis=False, go_class=None):\n",
    "    # Apply the extract, replace, and save logic in one function\n",
    "    result = extract_top_phylum_entries(\n",
    "        enrichment_df=df,\n",
    "        percentage_threshold=5.0,\n",
    "        go_analysis=go_analysis,\n",
    "        go_class=go_class\n",
    "    )\n",
    "    result.with_columns(\n",
    "        pl.col(\"Phylum\")\n",
    "        .str.replace(\"Candidatus \", \"C. \")\n",
    "        .str.replace(\"Candidate \", \"C. \")\n",
    "    ).write_csv(filename)\n",
    "    return result\n",
    "\n",
    "# Process top domains and families\n",
    "top_domains = process_and_save(enrichment_dfs['domains'], \"domains.csv\")\n",
    "top_families = process_and_save(enrichment_dfs['families'], \"families.csv\")\n",
    "\n",
    "# Process and concatenate top GO terms per GO class\n",
    "selected_go_terms = [\n",
    "    process_and_save(clustered_go_terms, None, go_analysis=True, go_class=go_class)\n",
    "    for go_class in classes\n",
    "]\n",
    "top_clustered_go_terms = pl.concat(selected_go_terms)\n",
    "top_clustered_go_terms.write_csv(\"go_terms.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499408f3-0907-47b8-acfe-8bc3c412c20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lollipop_plot(top_clustered_go_terms: pl.DataFrame, go_term_mapping: Dict[str, str], go_class: str) -> None:\n",
    "    \"\"\"\n",
    "    Create a lollipop plot with customized elements, sized for 180x57mm figure space.\n",
    "    \"\"\"\n",
    "    \n",
    "    top_clustered_go_terms = top_clustered_go_terms.filter((pl.col('Representative_LOR') != 0) & (pl.col('Class') == go_class)).to_pandas()\n",
    "    \n",
    "    # Sort data and create labels\n",
    "    df_sorted = top_clustered_go_terms.copy()\n",
    "    df_sorted['Component_Label'] = df_sorted['Representative_Description'] + ' (' + df_sorted['Phylum'] + ')'\n",
    "\n",
    "    # Sort by Phylum alphabetically and then by LOR within each Phylum (descending)\n",
    "    df_sorted = df_sorted.sort_values(['Phylum', 'Representative_LOR'], ascending=[True, False])\n",
    "\n",
    "    # Get cluster size distribution\n",
    "    cluster_sizes = sorted(df_sorted['Cluster_Size'].unique())\n",
    "    legend_sizes = [cluster_sizes[0], cluster_sizes[len(cluster_sizes)//4], cluster_sizes[len(cluster_sizes)//2], cluster_sizes[-1]]\n",
    "\n",
    "    # Adjust dot sizes for the smaller figure\n",
    "    min_size = 15 \n",
    "    max_size = 80 \n",
    "    sizes = np.log10(df_sorted['Cluster_Size'] + 1) * (max_size - min_size) + min_size\n",
    "\n",
    "    # Create color map based on negative log10 p-value\n",
    "    p_values = df_sorted['Adjusted_Meta_P_Value']\n",
    "    colors = -np.log10(p_values)\n",
    "    cmap = plt.colormaps.get_cmap('flare')\n",
    "    norm = mcolors.LogNorm(vmin=colors.min(), vmax=colors.max())\n",
    "    color_values = cmap(norm(colors))\n",
    "\n",
    "    plt.figure(figsize=(2.24, 18.49), dpi=300)  \n",
    "    \n",
    "    unique_phyla = df_sorted['Phylum'].unique()\n",
    "    for i, phylum in enumerate(unique_phyla):\n",
    "        phylum_indices = df_sorted[df_sorted['Phylum'] == phylum].index\n",
    "        if i % 2 == 0:\n",
    "            plt.axhspan(phylum_indices.min() - 0.5, phylum_indices.max() + 0.5, facecolor='grey', alpha=0.1, zorder=0)\n",
    "\n",
    "    # Create lollipop stems, heads, and error bars with adjusted line widths\n",
    "    for idx in range(len(df_sorted)):\n",
    "        row = df_sorted.iloc[idx]\n",
    "        plt.hlines(y=idx, xmin=0, xmax=row['Representative_LOR'], color=color_values[idx], linewidth=1) \n",
    "        plt.hlines(y=idx, xmin=max(0, row['Lower_CI']), xmax=row['Upper_CI'], color='black', linewidth=0.5) \n",
    "        plt.vlines(x=max(0, row['Lower_CI']), ymin=idx - 0.1, ymax=idx + 0.1, color='black', linewidth=1) \n",
    "        plt.vlines(x=row['Upper_CI'], ymin=idx - 0.1, ymax=idx + 0.1, color='black', linewidth=1)\n",
    "\n",
    "    # Scatter plot for lollipop heads\n",
    "    plt.scatter(df_sorted['Representative_LOR'], range(len(df_sorted)), color=color_values, s=sizes, zorder=3)\n",
    "\n",
    "    # Customize plot with adjusted font sizes\n",
    "    cleaned_labels = [re.sub(r\"\\s\\(.*?\\)\", \"\", label) for label in df_sorted['Component_Label']]\n",
    "    final_labels = [go_term_mapping.get(label, label) for label in cleaned_labels]\n",
    "    plt.yticks(range(len(df_sorted)), final_labels, fontsize=12)  \n",
    "    plt.xticks(ticks=np.arange(0, max(df_sorted['Upper_CI']) + 1, 2), fontsize=10) \n",
    "    plt.xlabel('ln(Enrichment)', fontsize=12) \n",
    "    plt.ylabel('')\n",
    "    plt.grid(axis='x', linestyle='-', alpha=0.7, zorder=0)\n",
    "    plt.xlim(0, max(df_sorted['Upper_CI']) + 1)\n",
    "    plt.ylim(-0.5, len(df_sorted['Representative_Description']))\n",
    "\n",
    "    # Adding Phylum labels to the right side with adjusted font size\n",
    "    phylum_positions = df_sorted.groupby('Phylum').apply(lambda x: (x.index.min() + x.index.max()) / 2.0)\n",
    "    for phylum, position in phylum_positions.items():\n",
    "        plt.text(x=max(df_sorted['Upper_CI']) + 0.6, y=position, \n",
    "                s=phylum.replace(\"Candidatus \", \"C. \").replace(\"Candidate \", \"C. \"),\n",
    "                fontsize=10, fontweight='bold', va='center', color='black') \n",
    "\n",
    "    sns.despine()\n",
    "    plt.tight_layout(pad=0.2) \n",
    "    plt.savefig(plots / f\"{go_class}_lollipop.svg\", bbox_inches='tight', pad_inches=0.1) \n",
    "    plt.close()\n",
    "\n",
    "    # Create separate legend plot with adjusted size\n",
    "    fig_legend = plt.figure(figsize=(1.5, 1.5)) \n",
    "    legend_elements = [plt.scatter([], [], s=np.log10(size + 1) * (max_size - min_size) + min_size, \n",
    "                                 color='black', alpha=0.7,\n",
    "                                 label=f'Cluster Size: {size}') for size in legend_sizes]\n",
    "    leg = fig_legend.legend(handles=legend_elements, title='Cluster Sizes', \n",
    "                          loc='center', fontsize=6, title_fontsize=7)\n",
    "    plt.axis('off')\n",
    "    fig_legend.savefig(plots / f'{go_class}_cluster_size_legend.svg', \n",
    "                      bbox_inches='tight', pad_inches=0.05)\n",
    "    plt.close()\n",
    "\n",
    "for go_class in classes:\n",
    "    create_lollipop_plot(top_clustered_go_terms, go_term_mapping, go_class)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9e0f1d-308d-4483-9075-07dc692fc877",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_clustered_go_terms = clustered_go_terms.filter((pl.col('Representative_LOR')!=0) & (pl.col(\"Adjusted_Meta_P_Value\")<0.05)).to_pandas()\n",
    "\n",
    "# Group by 'Phylum' and 'Class', then sum the counts\n",
    "grouped = filtered_clustered_go_terms.groupby(['Phylum', 'Class'])['Species_Count'].sum().unstack(fill_value=0)\n",
    "\n",
    "# Reset index \n",
    "grouped_data = grouped.reset_index()\n",
    "\n",
    "# Set Phylum as index \n",
    "grouped_data = grouped_data.set_index('Phylum')\n",
    "\n",
    "# Convert any string numbers to float in the dataframe\n",
    "for col in grouped_data.columns:\n",
    "    if col != 'Phylum':  \n",
    "        grouped_data[col] = pd.to_numeric(grouped_data[col], errors='coerce')\n",
    "\n",
    "# Define domain colors\n",
    "domain_colors = {\n",
    "    'Archaea': '#0072b2',\n",
    "    'Bacteria': '#e69f00',\n",
    "    'Eukaryota': '#009e73',\n",
    "    'Viruses': '#cc79a7'\n",
    "}\n",
    "\n",
    "# Define colors for GO term classes\n",
    "go_colors = {\n",
    "    'biological_process': '#D193AE',\n",
    "    'molecular_function': '#CDB497',\n",
    "    'cellular_component': '#83A7C4'\n",
    "}\n",
    "\n",
    "# Create phylum to lineage mapping\n",
    "phylum_to_lineage = {}\n",
    "for domain in domain_to_kingdom_to_phylum:\n",
    "    for kingdom in domain_to_kingdom_to_phylum[domain]:\n",
    "        phyla = domain_to_kingdom_to_phylum[domain][kingdom]\n",
    "        for phylum in phyla:\n",
    "            phylum_to_lineage[phylum] = (domain, kingdom)\n",
    "\n",
    "# Get all unique phyla \n",
    "all_phyla = grouped_data.index.unique()\n",
    "\n",
    "# Create a dictionary to store domain-wise phyla\n",
    "domain_wise_phyla = {domain: [] for domain in domain_colors.keys()}\n",
    "\n",
    "# Calculate total counts for each phylum (sum across all GO term classes)\n",
    "total_counts = grouped_data.sum(axis=1) \n",
    "\n",
    "# Sort phyla into their respective domains with counts\n",
    "for phylum in all_phyla:\n",
    "    domain = phylum_to_lineage.get(phylum, (None, None))[0]\n",
    "    if domain in domain_wise_phyla:\n",
    "        domain_wise_phyla[domain].append((phylum, total_counts[phylum]))\n",
    "\n",
    "# Sort phyla within each domain by total counts (descending)\n",
    "for domain in domain_wise_phyla:\n",
    "    domain_wise_phyla[domain].sort(key=lambda x: x[1], reverse=True)\n",
    "    domain_wise_phyla[domain] = [x[0] for x in domain_wise_phyla[domain]]\n",
    "\n",
    "# Create ordered list of phyla\n",
    "ordered_phyla = []\n",
    "for domain in domain_colors.keys():\n",
    "    ordered_phyla.extend(domain_wise_phyla[domain])\n",
    "\n",
    "# Reindex grouped data with the new order\n",
    "grouped_data = grouped_data.reindex(ordered_phyla)\n",
    "\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "gs = fig.add_gridspec(2, 20, height_ratios=[0.5, 10], hspace=0.05)\n",
    "\n",
    "ax_domains = fig.add_subplot(gs[0, :19])\n",
    "ax = fig.add_subplot(gs[1, :19])\n",
    "\n",
    "grouped_data.plot(kind='bar', stacked=True, ax=ax, \n",
    "                 color=[go_colors[col] for col in grouped_data.columns],\n",
    "                 legend=False,\n",
    "                 width=0.9)\n",
    "\n",
    "plt.xticks(rotation=45, ha='right', fontsize=8)\n",
    "plt.xlabel('', fontsize=12)\n",
    "plt.ylabel('Number of enriched GO Terms', fontsize=18)\n",
    "plt.title('')\n",
    "plt.grid(axis='y', linestyle='-', alpha=0.7)\n",
    "plt.yscale('log')\n",
    "\n",
    "ax_domains.axis('off')\n",
    "\n",
    "current_x = -0.5\n",
    "for domain in domain_colors.keys():\n",
    "    domain_phyla = domain_wise_phyla[domain]\n",
    "    if domain_phyla:\n",
    "        width = len(domain_phyla)\n",
    "        rect = plt.Rectangle((current_x, 0), width, 1,\n",
    "                           color=domain_colors[domain], alpha=0.8)\n",
    "        ax_domains.add_patch(rect)        \n",
    "        current_x += width\n",
    "\n",
    "ax_domains.set_xlim(-0.5, len(all_phyla) - 0.5)\n",
    "ax_domains.set_ylim(0, 1)\n",
    "\n",
    "x_labels = [label.replace(\"Candidatus \", \"C. \").replace(\"Candidate \", \"C. \") \n",
    "            for label in grouped_data.index]\n",
    "ax.set_xticklabels(x_labels, rotation=90, ha='center', fontsize=12)\n",
    "\n",
    "sns.despine()\n",
    "\n",
    "plt.savefig('stacked_bar_plot.svg', dpi=300, bbox_inches='tight', pad_inches=0)\n",
    "plt.show()\n",
    "\n",
    "# Create separate legend figure\n",
    "figsize_legend = (6, 2)\n",
    "fig_legend = plt.figure(figsize=figsize_legend)\n",
    "ax_legend = fig_legend.add_subplot(111)\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "\n",
    "label_mapping = {\n",
    "    'biological_process': 'Biological Process',\n",
    "    'molecular_function': 'Molecular Function',\n",
    "    'cellular_component': 'Cellular Component'\n",
    "}\n",
    "\n",
    "labels = [label_mapping[label] for label in labels]\n",
    "\n",
    "ax_legend.legend(handles, labels,\n",
    "               title='GO Term Class',\n",
    "               title_fontsize=12,\n",
    "               fontsize=10,\n",
    "               loc='center',\n",
    "               ncol=3)\n",
    "\n",
    "ax_legend.axis('off')\n",
    "\n",
    "plt.savefig('legend.svg', dpi=300, bbox_inches='tight', pad_inches=0)\n",
    "\n",
    "plt.close('all')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

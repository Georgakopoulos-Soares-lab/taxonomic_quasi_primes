{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f475cb-902b-4593-bab6-3bd3aa9e6a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "from typing import *\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "sns.set_context(\"paper\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185e5bfd-c756-4f80-8c79-783de807feb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base directory for data storage\n",
    "base_dir = Path(\"/storage/group/izg5139/default/lefteris/\")\n",
    "\n",
    "# Directory that contains the structural data \n",
    "structural_analysis_dir = base_dir / \"multi_species_structural_analysis_files/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5162ebb8-711c-42b9-88ad-7e1c856da28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists containing taxon ids for model organisms and global health risk organisms present in the dataset\n",
    "model_organisms_taxon_ids = [\n",
    "    3702, 6239, 237561, 7955, 44689, 7227, 83333, 3847, \n",
    "    9606, 243232, 10090, 39947, 10116, 559292, 284812, 4577,\n",
    "]\n",
    "\n",
    "global_health_taxon_ids = [\n",
    "    447093, 6279, 192222, 86049, 318479, 1352, 1442368, 71421,\n",
    "    85962, 1125630, 5671, 100816, 272631, 83332, 1299332, 242231, \n",
    "    1133849, 6282, 502779, 36329, 208964, 99287, 6183, 300267, 1391915, \n",
    "    93061, 171101, 6248, 36087, 185431, 353153, 6293\n",
    "]\n",
    "\n",
    "# Define organism categories\n",
    "organism_categories = {\n",
    "    \"Animals\": [\n",
    "        \"Homo sapiens\",\n",
    "        \"Caenorhabditis elegans\",\n",
    "        \"Drosophila melanogaster\",\n",
    "        \"Danio rerio\",\n",
    "        \"Mus musculus\",\n",
    "        \"Rattus norvegicus\"\n",
    "    ],\n",
    "    \"Plants\": [\n",
    "        \"Arabidopsis thaliana\",\n",
    "        \"Oryza sativa Japonica Group\",\n",
    "        \"Glycine max\",\n",
    "        \"Zea mays\"\n",
    "    ],\n",
    "    \"Single-celled\": [\n",
    "        \"Saccharomyces cerevisiae S288C\",\n",
    "        \"Schizosaccharomyces pombe 972h-\"\n",
    "    ],\n",
    "    \"Protozoan\": [\n",
    "        \"Trypanosoma cruzi strain CL Brener\",\n",
    "        \"Leishmania infantum\",\n",
    "        \"Trypanosoma brucei brucei TREU927\",\n",
    "        \"Plasmodium falciparum 3D7\"\n",
    "    ],\n",
    "    \"Helminths\": [\n",
    "        \"Brugia malayi\",\n",
    "        \"Onchocerca volvulus\",\n",
    "        \"Strongyloides stercoralis\",\n",
    "        \"Schistosoma mansoni\",\n",
    "        \"Dracunculus medinensis\",\n",
    "        \"Wuchereria bancrofti\"\n",
    "    ],\n",
    "    \"Fungi\": [\n",
    "        \"Cladophialophora carrionii\",\n",
    "        \"Sporothrix schenckii ATCC 58251\",\n",
    "        \"Madurella mycetomatis\",\n",
    "        \"Candida albicans SC5314\",\n",
    "        \"Histoplasma capsulatum G186AR\",\n",
    "        \"Fonsecaea pedrosoi CBS 271.37\",\n",
    "        \"Paracoccidioides lutzii Pb01\"\n",
    "    ],\n",
    "    \"Bacteria\": [\n",
    "        \"Campylobacter jejuni ATCC 700819\",\n",
    "        \"Helicobacter pylori 26695\"\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08884d50-70ae-46e1-9e31-1092215feb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the original file\n",
    "secondary_structures = pl.read_csv(structural_analysis_dir / \"secondary_structures.txt\", \n",
    "                                   separator =\"\\t\")\n",
    "\n",
    "# List of columns to process\n",
    "percentage_cols = [\n",
    "    \"Alpha_percent\", \"3_10_helix_percent\", \"Pi_helix_percent\",\n",
    "    \"Extended_percent\", \"Isolated_bridge_percent\", \"Turn_percent\",\n",
    "    \"Coil_percent\"\n",
    "]\n",
    "\n",
    "# Create expressions to replace \"N/A\" with \"0\" for each column\n",
    "expressions = [\n",
    "    pl.col(col).map_elements(lambda x: '0' if x == \"N/A\" else x, return_dtype=pl.Utf8)\n",
    "    for col in percentage_cols + [\"Predominant_structure\"]\n",
    "]\n",
    "secondary_structures = secondary_structures.with_columns(expressions)\n",
    "\n",
    "# Replace values in Predominant_structure\n",
    "secondary_structures = secondary_structures.with_columns(\n",
    "    pl.col(\"Predominant_structure\").replace('0', \"Disordered\")\n",
    ")\n",
    "\n",
    "# Split PDB_ID and create new columns\n",
    "secondary_structures = secondary_structures.with_columns([\n",
    "    pl.col(\"PDB_ID\").str.split('_').list.get(0).alias(\"Accession\"),\n",
    "    pl.col(\"PDB_ID\").str.split('_').list.get(1).cast(pl.Int64).alias(\"Start\"),\n",
    "    pl.col(\"PDB_ID\").str.split('_').list.get(2).cast(pl.Int64).alias(\"End\")\n",
    "])\n",
    "\n",
    "# Drop PDB_ID column\n",
    "secondary_structures = secondary_structures.drop(\"PDB_ID\")\n",
    "\n",
    "secondary_structures = secondary_structures.with_columns([\n",
    "    pl.col(\"Alpha_percent\").cast(pl.Float64),\n",
    "    pl.col(\"3_10_helix_percent\").cast(pl.Float64),\n",
    "    pl.col(\"Pi_helix_percent\").cast(pl.Float64),\n",
    "    pl.col(\"Extended_percent\").cast(pl.Float64),\n",
    "    pl.col(\"Isolated_bridge_percent\").cast(pl.Float64),\n",
    "    pl.col(\"Turn_percent\").cast(pl.Float64),\n",
    "    pl.col(\"Coil_percent\").cast(pl.Float64),\n",
    "])\n",
    "\n",
    "# Add structure percenteges to the disordered column\n",
    "secondary_structures = secondary_structures.with_columns([\n",
    "    pl.when(pl.col(\"Predominant_structure\") == \"Disordered\")\n",
    "    .then(100.0)\n",
    "    .otherwise(0.0)\n",
    "    .alias(\"Disordered_percent\")\n",
    "])\n",
    "\n",
    "# Reorder columns with select\n",
    "secondary_structures = secondary_structures.select(\n",
    "    [\"Accession\", \"Start\", \"End\"] + percentage_cols + [\"Disordered_percent\", \"Predominant_structure\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30ae2e4-6466-4727-a74a-9db75cef7565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data to map UniProt accession numbers to taxon ids\n",
    "accession_taxon_mappings = pl.read_csv(base_dir / \"peptide_match_files/uniprot_2024_01_reference_proteomes/reference_proteomes_2024_01_taxid_mappings.idmapping\", \n",
    "                                       separator='\\t',\n",
    "                                       new_columns = [\"Accession\", \"Database\", \"Taxon_ID\"]).drop(\"Database\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c954ec8-3be9-4610-87bf-2f8bd6c0b1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add taxon ids to the accessions\n",
    "sec_structures_with_mappings = secondary_structures.join(\n",
    "    accession_taxon_mappings,\n",
    "    on=\"Accession\",\n",
    "    how=\"left\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b66c0df-24be-4759-8455-fa23cfcac647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique Taxon_IDs \n",
    "unique_taxon_ids = sec_structures_with_mappings[\"Taxon_ID\"].unique().to_list()\n",
    "\n",
    "# Initialize dictionary for results\n",
    "taxon_names = {}\n",
    "\n",
    "# Search for scientific names on the taxon ids from the E-utilities of NCBI\n",
    "base_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils\"\n",
    "batch_size = 50\n",
    "\n",
    "# Process IDs in batches\n",
    "for i in range(0, len(unique_taxon_ids), batch_size):\n",
    "    batch = unique_taxon_ids[i:i + batch_size]\n",
    "    id_string = \",\".join(map(str, batch))\n",
    "    \n",
    "    # Construct the E-utilities URL\n",
    "    url = f\"{base_url}/esummary.fcgi?db=taxonomy&id={id_string}&retmode=json\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        # Extract scientific names from the response\n",
    "        for taxon_id in batch:\n",
    "            try:\n",
    "                taxon_data = data[\"result\"][str(taxon_id)]\n",
    "                scientific_name = taxon_data[\"scientificname\"]\n",
    "                taxon_names[taxon_id] = scientific_name\n",
    "            except KeyError:\n",
    "                taxon_names[taxon_id] = \"Not found\"\n",
    "                \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching batch {i//batch_size + 1}: {str(e)}\")\n",
    "        \n",
    "\n",
    "# Convert dictionary to DataFrame and join\n",
    "names_df = pl.DataFrame({\n",
    "    \"Taxon_ID\": list(taxon_names.keys()),\n",
    "    \"Scientific_Name\": list(taxon_names.values())\n",
    "})\n",
    "\n",
    "# Join scientific names to sec_structures_with_mappings\n",
    "sec_structures_with_mappings = sec_structures_with_mappings.join(\n",
    "    names_df,\n",
    "    on=\"Taxon_ID\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Replace the specific strain name\n",
    "sec_structures_with_mappings = sec_structures_with_mappings.with_columns(\n",
    "    pl.col(\"Scientific_Name\").map_elements(\n",
    "        lambda x: \"Campylobacter jejuni ATCC 700819\" \n",
    "        if x == \"Campylobacter jejuni subsp. jejuni NCTC 11168 = ATCC 700819\" \n",
    "        else x,\n",
    "        return_dtype = pl.Utf8\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3946c6ec-787f-4c20-96a3-e40e87f2ce1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split original DataFrame to model organisms and global health risk organisms\n",
    "model_organisms_df = sec_structures_with_mappings.filter(pl.col(\"Taxon_ID\").is_in(model_organisms_taxon_ids))\n",
    "global_health_df = sec_structures_with_mappings.filter(pl.col(\"Taxon_ID\").is_in(global_health_taxon_ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fee8644-4b9f-4632-9c42-8be133d0c1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def secondary_structure_kruskal_test(df):\n",
    "    \"\"\"\n",
    "    Perform Kruskal-Wallis test on secondary structure percentage columns.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get all percentage columns\n",
    "    percent_columns = [\n",
    "        'Alpha_percent', '3_10_helix_percent', 'Pi_helix_percent', \n",
    "        'Extended_percent', 'Isolated_bridge_percent', 'Turn_percent', \n",
    "        'Coil_percent', 'Disordered_percent'\n",
    "    ]\n",
    "    \n",
    "    # Filter out columns where all values are 0\n",
    "    non_zero_cols = [\n",
    "        col for col in percent_columns \n",
    "        if df.select(pl.col(col)).sum().item() > 0\n",
    "    ]\n",
    "    \n",
    "    # Convert each non-zero column to a list for the Kruskal-Wallis test\n",
    "    data_for_test = [\n",
    "        df.select(pl.col(col)).to_series().to_list()\n",
    "        for col in non_zero_cols\n",
    "    ]\n",
    "    \n",
    "    # Perform Kruskal-Wallis H-test\n",
    "    h_statistic, p_value = stats.kruskal(*data_for_test)\n",
    "    \n",
    "    return {\n",
    "        'h_statistic': h_statistic,\n",
    "        'df': len(non_zero_cols) - 1,\n",
    "        'p_value': p_value,\n",
    "        'n': len(df),\n",
    "        'groups_tested': non_zero_cols\n",
    "    }\n",
    "\n",
    "results = secondary_structure_kruskal_test(global_health_df)\n",
    "\n",
    "print(f\"H = {results['h_statistic']:.2f}, df = {results['df']},\"\n",
    "      f\"p < 0.001, n = {results['n']}).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e02d64-b9b5-459e-89d9-0713dcbe7509",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_visualisation_data(structural_dataframe: pl.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculates the mean secondary structure percentage for secondary structure type and for each species present in the dataset.\n",
    "    \"\"\"\n",
    "    # Calculate percentage means\n",
    "    grouped = (structural_dataframe\n",
    "        .group_by(\"Scientific_Name\")\n",
    "        .agg([\n",
    "            pl.mean(col).alias(f\"{col}\") \n",
    "            for col in percentage_cols + [\"Disordered_percent\"]\n",
    "        ])\n",
    "\n",
    "    )\n",
    "\n",
    "    # Convert Polars dataframe to pandas for later visualisations\n",
    "    grouped_pd = grouped.to_pandas()\n",
    "\n",
    "    # Set \"Scientific_Name\" as the index\n",
    "    grouped_pd.set_index(\"Scientific_Name\", inplace=True)\n",
    "\n",
    "    # Select the data for clustering\n",
    "    data_for_clustering = grouped_pd[percentage_cols + [\"Disordered_percent\"]]\n",
    "    data_for_clustering = data_for_clustering.rename(columns={\"Alpha_percent\": \"Alpha_helix_percent\"})\n",
    "    \n",
    "    # Create a mapping dictionary that maps organism names to their categories\n",
    "    organism_to_category = {}\n",
    "    for category, organisms in organism_categories.items():\n",
    "        for organism in organisms:\n",
    "            organism_to_category[organism] = category\n",
    "\n",
    "    # Add new column to the dataframe\n",
    "    data_for_clustering['Category'] = data_for_clustering.index.map(organism_to_category)\n",
    "\n",
    "    return data_for_clustering\n",
    "\n",
    "model_organisms_vis = create_visualisation_data(model_organisms_df)\n",
    "global_health_vis = create_visualisation_data(global_health_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f973ab27-959f-48a3-812d-f48c8f1b8ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_font_sizes(fig_width: float, \n",
    "                         fig_height: float) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Helper function to dynamically calculate font sizes for plot elements based on figure dimensions.\n",
    "    \"\"\"\n",
    "    min_dimension = min(fig_width, fig_height)\n",
    "    base_size = min_dimension * 2\n",
    "    return {\n",
    "        'axis_label': max(base_size * 1.35, 10),\n",
    "        'tick_label': max(base_size * 1.05, 8),\n",
    "        'legend': max(base_size * 1.2, 8),\n",
    "        'metric_value': max(base_size * 1, 8),\n",
    "        'table': max(base_size * 0.9, 8)\n",
    "    }\n",
    "\n",
    "def create_category_legend(category_colors: dict, output_file_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Creates a separate legend figure for the categories.\n",
    "    \"\"\"\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(3, 4))\n",
    "    \n",
    "    # Create patches for each category\n",
    "    patches = []\n",
    "    for label, color in category_colors.items():\n",
    "        patch = plt.Rectangle((0, 0), 1, 1, fc=color, label=label)\n",
    "        patches.append(patch)\n",
    "    \n",
    "    # Add the patches to the legend\n",
    "    ax.legend(patches, \n",
    "             category_colors.keys(),\n",
    "             title='Categories',\n",
    "             loc='center',\n",
    "             fontsize=12,\n",
    "             title_fontsize=14,\n",
    "             frameon=True)\n",
    "    \n",
    "    # Hide the axes\n",
    "    ax.set_axis_off()\n",
    "    \n",
    "    # Save the legend with a tight layout\n",
    "    plt.savefig(output_file_path, \n",
    "                bbox_inches='tight',\n",
    "                pad_inches=0.1,\n",
    "                dpi=300,\n",
    "                transparent=True)\n",
    "    plt.close()\n",
    "\n",
    "def create_clustermap(visualisation_data: pd.DataFrame, colorbar: str, output_file_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Creates a clustermap visualisation of the secondary structures for each species,\n",
    "    with rows colored based on organism categories.\n",
    "    \"\"\"\n",
    "    \n",
    "    fontsizes = calculate_font_sizes(12,9)\n",
    "    # Clean up column names\n",
    "    clean_col_names = [col.replace(\"_percent\", \"\").replace(\"_\", \" \")\n",
    "                      for col in visualisation_data.columns[:-1]]  # Exclude Category column\n",
    "    viz_data = visualisation_data.drop('Category', axis=1)  # Remove Category from main data\n",
    "    viz_data.columns = clean_col_names\n",
    "    \n",
    "    # Create a color palette for categories\n",
    "    category_colors = {\n",
    "        'Helminths': '#9375E0',\n",
    "        'Fungi': '#759CE0',\n",
    "        'Bacteria': '#E0CB74',\n",
    "        'Animals': '#8B8777',     \n",
    "        'Plants': '#363221',      \n",
    "        'Single-celled': '#777E8B',\n",
    "        'Protozoan': '#7D778B'\n",
    "    }\n",
    "    \n",
    "    # Create row colors based on categories\n",
    "    row_colors = visualisation_data['Category'].map(category_colors)\n",
    "    \n",
    "    # Create the clustermap\n",
    "    g = sns.clustermap(\n",
    "        data=viz_data,\n",
    "        cmap=colorbar,\n",
    "        metric='euclidean',\n",
    "        method='ward',\n",
    "        annot=True,\n",
    "        fmt=\".2f\",\n",
    "        annot_kws={'size': 14},\n",
    "        xticklabels=clean_col_names,\n",
    "        yticklabels=True,\n",
    "        linewidths=0.5,\n",
    "        linecolor=\"black\",\n",
    "        figsize=(16, 12),\n",
    "        dendrogram_ratio=0.2,\n",
    "        tree_kws={\"linewidths\": 1.0},\n",
    "        row_colors=row_colors\n",
    "    )\n",
    "    \n",
    "    # Customize the plot\n",
    "    g.ax_heatmap.set_xlabel(\"\")\n",
    "    g.ax_heatmap.set_ylabel(\"\")\n",
    "    \n",
    "    # Rotate axis labels\n",
    "    g.ax_heatmap.set_xticklabels(\n",
    "        g.ax_heatmap.get_xticklabels(),\n",
    "        rotation=45,\n",
    "        ha=\"right\",\n",
    "        fontsize=fontsizes['tick_label']\n",
    "    )\n",
    "    \n",
    "    g.ax_heatmap.set_yticklabels(\n",
    "        g.ax_heatmap.get_yticklabels(),\n",
    "        rotation=0,\n",
    "        va=\"center\",\n",
    "        fontsize=fontsizes['tick_label']\n",
    "    )\n",
    "    \n",
    "    # Adjust layout to prevent label cutoff\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the clustermap\n",
    "    plt.savefig(output_file_path, bbox_inches='tight', pad_inches=0)\n",
    "    plt.show()\n",
    "    \n",
    "    # Create and save the separate legend\n",
    "    legend_file_path = output_file_path.replace('.svg', '_legend.svg')\n",
    "    create_category_legend(category_colors, legend_file_path)\n",
    "\n",
    "create_clustermap(model_organisms_vis, \"viridis\", \"model_organisms_sec_structures.svg\")\n",
    "create_clustermap(global_health_vis, \"cividis\", \"global_health_sec_structures.svg\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "707c0dde-d072-45a1-99ef-a66c8ded0785",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "from typing import *\n",
    "from pathlib import Path\n",
    "import polars as pl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b44c2a5-a6a2-4a92-b321-57d72d6f62a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base directory where files are stored\n",
    "base_dir = Path('/storage/group/izg5139/default/lefteris/')\n",
    "\n",
    "# Analysis directories\n",
    "reference_mappings_dir = base_dir / 'qp_peptides_over_90_per_phylum'\n",
    "multi_species_goea_files_dir = base_dir / 'multi_species_goea_files'\n",
    "\n",
    "# Output directories setup\n",
    "output_dirs = {\n",
    "    'formated_reference_mappings': reference_mappings_dir / \"formated_reference_mappings\",\n",
    "    'goea_results': multi_species_goea_files_dir / 'multi_species_goea_results',\n",
    "    'phylum_associations': multi_species_goea_files_dir / 'phylum_associations',\n",
    "    'phylum_study_populations': multi_species_goea_files_dir / 'phylum_study_populations',\n",
    "    'phylum_background_populations': multi_species_goea_files_dir / 'phylum_background_populations'\n",
    "}\n",
    "\n",
    "# Create all output directories\n",
    "for dir_path in output_dirs.values():\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "# Contains associations of UniProt protein accessions to Gene Ontology terms\n",
    "uniprot_gaf = pl.read_parquet(base_dir / \"multi_species_goea_files/goa_uniprot_all.parquet\")\n",
    "\n",
    "# Contains mappins of UniProt protein accessions to Taxon IDs\n",
    "taxon_id_mappings = pl.read_parquet(base_dir / 'multi_species_goea_files/reference_proteomes_2024_01_taxid_mappings.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3880b7f-b3a0-45fe-8608-d4f01ead33db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_peptide_match_results(file_path: str) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Reads and formats Peptide Match results into a Polars DataFrame.\n",
    "    \"\"\"\n",
    "    mappings = pl.read_csv(\n",
    "        file_path,\n",
    "        separator='\\t',\n",
    "        comment_prefix='#',\n",
    "        new_columns=[\"QP_peptide\", \"Mappings\", \"Protein_length\", \"Match_start\", \"Match_end\"]\n",
    "    )\n",
    "\n",
    "    mappings = mappings.with_columns([\n",
    "        pl.col(\"Mappings\").str.split(\"|\").list.get(1).alias(\"Protein_accession\"),\n",
    "        pl.col(\"Mappings\").str.split(\"|\").list.get(2).alias(\"Protein_Name\")\n",
    "    ])\n",
    "\n",
    "    mappings = mappings.select(\n",
    "        \"QP_peptide\", \"Protein_accession\", \"Protein_Name\",\n",
    "        \"Protein_length\", \"Match_start\", \"Match_end\"\n",
    "    )\n",
    "\n",
    "    return mappings\n",
    "\n",
    "def add_taxon_id(peptide_match_mappings: pl.DataFrame, taxon_ids: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Adds a Taxon_ID column to the Peptide Match results DataFrame based on matching Protein_accession values.\n",
    "    \"\"\"\n",
    "    peptide_match_mappings_with_taxon_ids = peptide_match_mappings.join(\n",
    "        taxon_ids,\n",
    "        left_on=\"Protein_accession\",\n",
    "        right_on=\"Protein_accession\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "    \n",
    "    return peptide_match_mappings_with_taxon_ids.drop_nulls() # Nulls in taxon id show isoforms\n",
    "\n",
    "def filter_and_count_accessions(mappings: pl.DataFrame, min_count: int = 10):\n",
    "    \"\"\"\n",
    "    Filters Taxon IDs based on the number of proteins that contain Quasi Prime peptides. \n",
    "    Taxon IDs with a protein count less than 10 are filtered so that downstream analyses are statisticaly reliable. \n",
    "    Also, reduces noise.\n",
    "    \"\"\"\n",
    "    # Count the number of proteins for  each Taxon ID\n",
    "    accession_counts = mappings.group_by('Taxon_ID').agg(\n",
    "        pl.count('Protein_accession').alias('accession_count')\n",
    "    )\n",
    "    accession_counts = accession_counts.sort('accession_count', descending=True)\n",
    "    accession_counts = accession_counts.filter(pl.col('accession_count') > min_count)\n",
    "\n",
    "    # Extract unique Taxon IDs\n",
    "    unique_ids = accession_counts['Taxon_ID'].unique()\n",
    "    \n",
    "    # Filter Peptide Match results\n",
    "    filtered_mappings = mappings.filter(pl.col('Taxon_ID').is_in(unique_ids))\n",
    "    \n",
    "    return filtered_mappings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f8c8768-a2cd-4253-a935-4f8cd4fc208c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_mapping_files(directory_path):\n",
    "    \"\"\"\n",
    "    Process all files matching *_reference_mappings.txt pattern in the given directory, \n",
    "    store results in a dictionary, save each formated dataframe to TXT file, and filter Taxon IDs that have a low protein count.\n",
    "    \"\"\"\n",
    "    # Dictionary to store results\n",
    "    results = {}\n",
    "    \n",
    "    # Pattern to match files\n",
    "    pattern = os.path.join(directory_path, \"*_reference_mappings.txt\")\n",
    "    \n",
    "    # Find all matching files\n",
    "    matching_files = glob.glob(pattern)\n",
    "        \n",
    "    # Process each file\n",
    "    for filepath in matching_files:\n",
    "        # Extract the base filename\n",
    "        filename = os.path.basename(filepath)\n",
    "        \n",
    "        # Extract the key (part before \"reference\")\n",
    "        key = filename.split('_reference')[0].strip()\n",
    "        \n",
    "        # Process the file\n",
    "        results[key] = read_peptide_match_results(filepath)\n",
    "        results[key] = add_taxon_id(results[key], taxon_id_mappings)\n",
    "        \n",
    "        # Save to TXT\n",
    "        output_path = os.path.join(output_dirs['formated_reference_mappings'], f\"{key}_formated_reference_mappings.txt\")\n",
    "        results[key].write_csv(output_path, separator = '\\t')\n",
    "        \n",
    "        # Filter low protein count Taxon IDs\n",
    "        results[key] = filter_and_count_accessions(results[key])\n",
    "    \n",
    "    return results\n",
    "\n",
    "processed_reference_mappings_dict = process_mapping_files(reference_mappings_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "174ed241-5b46-4a6d-8953-1fc6cd17ab5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_associations(taxon_ids: Union[pl.Series, List[int]]) -> Dict[int, Dict[str, List[str]]]:\n",
    "    \"\"\"\n",
    "    Creates a nested dictionary mapping taxon IDs to their protein-GO term associations.\n",
    "    The nested dictionary is of this format\n",
    "    Phylum\n",
    "        Taxon ID\n",
    "            Protein\n",
    "                Associated GO terms\n",
    "    \"\"\"\n",
    "    # Creates a set with unique Taxon IDs for an efficient lookup\n",
    "    taxon_id_set = set(taxon_ids.to_numpy())\n",
    "    \n",
    "    # Filters the original GAF file to keep only the needed Taxon IDs\n",
    "    filtered_uniprot_gaf = uniprot_gaf.filter(pl.col(\"Taxon_ID\").is_in(taxon_id_set))\n",
    "    \n",
    "    # Group the filtered data by Taxon_ID and Protein_accession and aggregate GO terms for each protein within each taxon\n",
    "    grouped_uniprot_gaf = (filtered_uniprot_gaf\n",
    "                           .group_by(['Taxon_ID', 'Protein_accession'])\n",
    "                           .agg(pl.col('GO_term').alias('GO_terms'))\n",
    "                           .sort('Taxon_ID'))\n",
    "    associations = {}\n",
    "    \n",
    "    # Process each Taxon ID\n",
    "    for taxon_id, group in grouped_uniprot_gaf.group_by('Taxon_ID'):\n",
    "        protein_go_dict = {protein: go_terms.to_list() for protein, go_terms in zip(group['Protein_accession'], group['GO_terms'])}\n",
    "        associations[int(taxon_id[0])] = protein_go_dict\n",
    "        \n",
    "    return associations\n",
    "\n",
    "def process_and_save_taxonomic_associations(\n",
    "    processed_reference_mappings_dict: Dict[str, pl.DataFrame]) -> Dict[str, Dict[int, Dict[str, List[str]]]]:\n",
    "    \"\"\"\n",
    "    Process each Peptide Match results DataFrame, create protein-GO term associations, and save results to JSON files.\n",
    "    \"\"\"\n",
    "    # Initialize result dictionary\n",
    "    taxonomic_associations = {}\n",
    "       \n",
    "    # Process each phylum's DataFrame and save results\n",
    "    for phylum, df in processed_reference_mappings_dict.items():\n",
    "        # Get unique taxon IDs for this phylum\n",
    "        taxon_ids = df['Taxon_ID'].unique()\n",
    "        \n",
    "        # Create associations for these taxon IDs\n",
    "        phylum_associations = create_associations(taxon_ids)\n",
    "        \n",
    "        # Store in result dictionary\n",
    "        taxonomic_associations[phylum] = phylum_associations\n",
    "        \n",
    "        # Save this phylum's associations to a JSON file\n",
    "        output_file = output_dirs['phylum_associations'] / f\"{phylum}_associations.json\"\n",
    "        with open(output_file, 'w') as f:\n",
    "            json.dump(phylum_associations, f, indent=2)\n",
    "    \n",
    "    return taxonomic_associations\n",
    "\n",
    "taxonomic_associations = process_and_save_taxonomic_associations(\n",
    "    processed_reference_mappings_dict\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bda42d2-b37e-4771-85ca-3d4106072670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_populations(mappings: pl.DataFrame) -> Dict[int, List[str]]:\n",
    "    \"\"\"\n",
    "    Creates a dictionary mapping taxon IDs to their associated protein accessions.\n",
    "    The dictionary is of this format\n",
    "    Phylum\n",
    "        Taxon ID\n",
    "            Proteins\n",
    "    \"\"\"\n",
    "    # Group the data by Taxon_ID and collect unique protein accessions for each taxon\n",
    "    taxon_populations = (\n",
    "        mappings.group_by(\"Taxon_ID\")\n",
    "        .agg(pl.col(\"Protein_accession\").unique().alias(\"Protein_accessions\"))\n",
    "        .sort(\"Taxon_ID\")\n",
    "    )\n",
    "    # Convert the grouped data into a dictionary:\n",
    "    populations = dict(zip(\n",
    "        taxon_populations[\"Taxon_ID\"].to_list(),\n",
    "        taxon_populations[\"Protein_accessions\"].to_list()\n",
    "    ))\n",
    "    \n",
    "    return populations\n",
    "\n",
    "def process_and_save_populations(\n",
    "    processed_reference_mappings_dict: Dict[str, pl.DataFrame]) -> Tuple[Dict[str, Dict[int, List[str]]], Dict[str, Dict[int, List[str]]]]:\n",
    "    \"\"\"\n",
    "    Process each Peptide Match result DataFrame alongside the GAF file to create both study and background populations,\n",
    "    and save them to separate JSON files by phylum.\n",
    "    \n",
    "    The Quasi Prime containing proteins per Phylum are considered as study populations while \n",
    "    all the proteins that have associated GO terms per Phylum are considered as background populations \n",
    "    \"\"\"\n",
    "    # Initialize study and background dictionaries\n",
    "    study_populations = {}\n",
    "    background_populations = {}\n",
    "        \n",
    "    # Process each phylum\n",
    "    for phylum, df in processed_reference_mappings_dict.items():\n",
    "        \n",
    "        # Create study populations for this phylum\n",
    "        phylum_study_populations = create_populations(df)\n",
    "        study_populations[phylum] = phylum_study_populations\n",
    "        \n",
    "        # Get unique taxon IDs for this phylum\n",
    "        taxon_ids = list(phylum_study_populations.keys())\n",
    "        \n",
    "        # Filter uniprot_gaf for these taxon IDs and create background populations\n",
    "        filtered_uniprot = (\n",
    "            uniprot_gaf\n",
    "            .filter(pl.col(\"Taxon_ID\").is_in(taxon_ids))\n",
    "            .group_by(\"Taxon_ID\")\n",
    "            .agg(pl.col(\"Protein_accession\").unique().alias(\"Protein_accessions\"))\n",
    "            .sort(\"Taxon_ID\")\n",
    "        )\n",
    "        \n",
    "        phylum_background_populations = dict(zip(\n",
    "            filtered_uniprot[\"Taxon_ID\"].to_list(),\n",
    "            filtered_uniprot[\"Protein_accessions\"].to_list()\n",
    "        ))\n",
    "        background_populations[phylum] = phylum_background_populations\n",
    "        \n",
    "        # Save study populations\n",
    "        with open(output_dirs['phylum_study_populations'] / f\"{phylum}_study_populations.json\", 'w') as f:\n",
    "            json.dump(phylum_study_populations, f, indent=2)\n",
    "            \n",
    "        # Save background populations\n",
    "        with open(output_dirs['phylum_background_populations'] / f\"{phylum}_background_populations.json\", 'w') as f:\n",
    "            json.dump(phylum_background_populations, f, indent=2)\n",
    "    \n",
    "    return study_populations, background_populations\n",
    "\n",
    "study_populations, background_populations = process_and_save_populations(\n",
    "    processed_reference_mappings_dict\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
